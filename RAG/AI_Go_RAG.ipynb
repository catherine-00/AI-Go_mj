{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7091d29e",
   "metadata": {},
   "source": [
    "# RAG + LLM -> 퀴즈, 해설 생성\n",
    "- LLM : GPT-oss 20b 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5173d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "torch version: 2.6.0+cu124\n",
      "cuda version reported by torch: 12.4\n",
      "gpu: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"cuda version reported by torch:\", torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783a1ba",
   "metadata": {},
   "source": [
    "## vector 임베딩 후 검색하는 코드 (기본)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f57487",
   "metadata": {},
   "source": [
    "### 상황 하나 당 여러 문제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665cbb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 기존 벡터스토어 로드 중...\n",
      "\n",
      "📄 문서 1\n",
      "▶ 페이지 번호 : 7\n",
      "▶ 전체 내용:\n",
      "passage: 제18조의2제1항 각 호에 따른 도로 또는 차로를 말한다.\n",
      "8. “자전거도로”란 안전표지, 위험방지용 울타리나 그와 비슷한 인공구조물로 경계를 표시하여 자전거 및 개인형 이\n",
      "동장치가 통행할 수 있도록 설치된 「자전거 이용 활성화에 관한 법률」 제3조 각 호의 도로를 말한다.\n",
      "9. “자전거횡단도”란 자전거 및 개인형 이동장치가 일반도로를 횡단할 수 있도록 안전표지로 표시한 도로의 부분을\n",
      "말한다.\n",
      "10. “보도”(步道)란 연석선, 안전표지나 그와 비슷한 인공구조물로 경계를 표시하여 보행자(유모차, 보행보조용 의자\n",
      "차, 노약자용 보행기 등 행정안전부령으로 정하는 기구ㆍ장치를 이용하여 통행하는 사람 및 제21호의3에 따른 실\n",
      "외이동로봇을 포함한다. 이하 같다)가 통행할 수 있도록 한 도로의 부분을 말한다.\n",
      "11. “길가장자리구역”이란 보도와 차도가 구분되지 아니한 도로에서 보행자의 안전을 확보하기 위하여 안전표지 등\n",
      "으로 경계를 표시한 도로의 가장자리 부분을 말한다.\n",
      "12. “횡단보도”란 보행자가 도로를 횡단할 수 있도록 안전표지로 표시한 도로의 부분을 말한다.\n",
      "13. “교차로”란 ‘십’자로, ‘T’자로나 그 밖에 둘 이상의 도로(보도와 차도가 구분되어 있는 도로에서는 차도를 말한다\n",
      ")가 교차하는 부분을 말한다.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 2\n",
      "▶ 페이지 번호 : 19\n",
      "▶ 전체 내용:\n",
      "passage: 법제처                                                            19                                                       국가법령정보센터\n",
      "도로교통법\n",
      "제23조(끼어들기의 금지) 모든 차의 운전자는 제22조제2항 각 호의 어느 하나에 해당하는 다른 차 앞으로 끼어들지 못\n",
      "한다.\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제24조(철길 건널목의 통과) ① 모든 차 또는 노면전차의 운전자는 철길 건널목(이하 “건널목”이라 한다)을 통과하려는\n",
      "경우에는 건널목 앞에서 일시정지하여 안전한지 확인한 후에 통과하여야 한다. 다만, 신호기 등이 표시하는 신호에\n",
      "따르는 경우에는 정지하지 아니하고 통과할 수 있다. <개정 2018. 3. 27.>\n",
      "② 모든 차 또는 노면전차의 운전자는 건널목의 차단기가 내려져 있거나 내려지려고 하는 경우 또는 건널목의 경보\n",
      "기가 울리고 있는 동안에는 그 건널목으로 들어가서는 아니 된다.<개정 2018. 3. 27.>\n",
      "③ 모든 차 또는 노면전차의 운전자는 건널목을 통과하다가 고장 등의 사유로 건널목 안에서 차 또는 노면전차를\n",
      "운행할 수 없게 된 경우에는 즉시 승객을 대피시키고 비상신호기 등을 사용하거나 그 밖의 방법으로 철도공무원이\n",
      "나 경찰공무원에게 그 사실을 알려야 한다.<개정 2018. 3. 27.>\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제25조(교차로 통행방법) ① 모든 차의 운전자는 교차로에서 우회전을 하려는 경우에는 미리 도로의 우측 가장자리를\n",
      "서행하면서 우회전하여야 한다. 이 경우 우회전하는 차의 운전자는 신호에 따라 정지하거나 진행하는 보행자 또는\n",
      "자전거등에 주의하여야 한다. <개정 2020. 6. 9.>\n",
      "② 모든 차의 운전자는 교차로에서 좌회전을 하려는 경우에는 미리 도로의 중앙선을 따라 서행하면서 교차로의 중\n",
      "심 안쪽을 이용하여 좌회전하여야 한다. 다만, 시ㆍ도경찰청장이 교차로의 상황에 따라 특히 필요하다고 인정하여\n",
      "지정한 곳에서는 교차로의 중심 바깥쪽을 통과할 수 있다.<개정 2020. 12. 22.>\n",
      "③ 제2항에도 불구하고 자전거등의 운전자는 교차로에서 좌회전하려는 경우에는 미리 도로의 우측 가장자리로 붙\n",
      "어 서행하면서 교차로의 가장자리 부분을 이용하여 좌회전하여야 한다.<개정 2020. 6. 9.>\n",
      "④ 제1항부터\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 3\n",
      "▶ 페이지 번호 : 24\n",
      "▶ 전체 내용:\n",
      "passage: 제39조(승차 또는 적재의 방법과 제한) ① 모든 차의 운전자는 승차 인원, 적재중량 및 적재용량에 관하여 대통령령으\n",
      "로 정하는 운행상의 안전기준을 넘어서 승차시키거나 적재한 상태로 운전하여서는 아니 된다. 다만, 출발지를 관할\n",
      "하는 경찰서장의 허가를 받은 경우에는 그러하지 아니하다.\n",
      "② 제1항 단서에 따른 허가를 받으려는 차가 「도로법」 제77조제1항 단서에 따른 운행허가를 받아야 하는 차에 해\n",
      "당하는 경우에는 제14조제4항을 준용한다.<신설 2014. 12. 30.>\n",
      "③ 모든 차 또는 노면전차의 운전자는 운전 중 타고 있는 사람 또는 타고 내리는 사람이 떨어지지 아니하도록 하기\n",
      "위하여 문을 정확히 여닫는 등 필요한 조치를 하여야 한다.<개정 2014. 12. 30., 2018. 3. 27.>\n",
      "④ 모든 차의 운전자는 운전 중 실은 화물이 떨어지지 아니하도록 덮개를 씌우거나 묶는 등 확실하게 고정될 수 있\n",
      "도록 필요한 조치를 하여야 한다.<개정 2014. 12. 30.>\n",
      "⑤ 모든 차의 운전자는 영유아나 동물을 안고 운전 장치를 조작하거나 운전석 주위에 물건을 싣는 등 안전에 지장\n",
      "을 줄 우려가 있는 상태로 운전하여서는 아니 된다.<개정 2014. 12. 30.>\n",
      "⑥ 시ㆍ도경찰청장은 도로에서의 위험을 방지하고 교통의 안전과 원활한 소통을 확보하기 위하여 필요하다고 인정\n",
      "하는 경우에는 차의 운전자에 대하여 승차 인원, 적재중량 또는 적재용량을 제한할 수 있다.<개정 2014. 12. 30.,\n",
      "2020. 12. 22.>\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제39조의2(적재량 측정자료의 제공) ① 시ㆍ도경찰청장은 운전자가 제39조제1항에 따른 적재중량과 적재용량에 관한\n",
      "안전기준을 위반하였는지 여부를 확인하기 위하여 필요한 경우 「도로법」에 따른 도로관리청(「도로법」 제112조에\n",
      "따라 국토교통부장관의 권한을 대행하는 한국도로공사를 포함한다. 이하 이 조에서 같다)에 같은 법 제77조제4항에\n",
      "따라 적재량을 측정한 자료(이하 “적재량 측정자료”라 한다)의 제공을 요청할 수 있다.\n",
      "② 제1항에 따라 적재량 측정자료의 제공을 요청받은 도로관리청은 특별한 사유가 없으면 이를 제공하여야 한다.\n",
      "③ 제1항에 따른 자료 제공 요청의 방법, 범위 등에 관한 사항은 대통령령으로 정한다.\n",
      "[본조신설 2025. 1. 7.]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 4\n",
      "▶ 페이지 번호 : 12\n",
      "▶ 전체 내용:\n",
      "passage: 법제처                                                            12                                                       국가법령정보센터\n",
      "도로교통법\n",
      "제7조의2(고령운전자 표지) ① 국가 또는 지방자치단체는 고령운전자의 안전운전 및 교통사고 예방을 위하여 행정안전\n",
      "부령으로 정하는 바에 따라 고령운전자가 운전하는 차임을 나타내는 표지(이하 “고령운전자 표지”라 한다)를 제작하\n",
      "여 배부할 수 있다.\n",
      "② 고령운전자는 다른 차의 운전자가 쉽게 식별할 수 있도록 차에 고령운전자 표지를 부착하고 운전할 수 있다.\n",
      "[본조신설 2023. 1. 3.]\n",
      " \n",
      "       제2장 보행자의 통행방법\n",
      " \n",
      "제8조(보행자의 통행) ① 보행자는 보도와 차도가 구분된 도로에서는 언제나 보도로 통행하여야 한다. 다만, 차도를 횡\n",
      "단하는 경우, 도로공사 등으로 보도의 통행이 금지된 경우나 그 밖의 부득이한 경우에는 그러하지 아니하다.\n",
      "② 보행자는 보도와 차도가 구분되지 아니한 도로 중 중앙선이 있는 도로(일방통행인 경우에는 차선으로 구분된 도\n",
      "로를 포함한다)에서는 길가장자리 또는 길가장자리구역으로 통행하여야 한다.<개정 2021. 10. 19.>\n",
      "③ 보행자는 다음 각 호의 어느 하나에 해당하는 곳에서는 도로의 전 부분으로 통행할 수 있다. 이 경우 보행자는\n",
      "고의로 차마의 진행을 방해하여서는 아니 된다.<개정 2022. 1. 11.>\n",
      "1. 보도와 차도가 구분되지 아니한 도로 중 중앙선이 없는 도로(일방통행인 경우에는 차선으로 구분되지 아니한 도\n",
      "로에 한정한다. 이하 같다)\n",
      "2. 보행자우선도로\n",
      "④ 보행자는 보도에서는 우측통행을 원칙으로 한다.<개정 2021. 10. 19.>\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제8조의2(실외이동로봇 운용자의 의무) ① 실외이동로봇을 운용하는 사람(실외이동로봇을 조작ㆍ관리하는 사람을 포\n",
      "함하며, 이하 “실외이동로봇 운용자”라 한다)은 실외이동로봇의 운용 장치와 그 밖의 장치를 정확하게 조작하여야 한\n",
      "다.\n",
      "② 실외이동로봇 운용자는 실외이동로봇의 운용 장치를 도로의 교통상황과 실외이동로봇의 구조 및 성능에 따라\n",
      "차, 노면전차 또는 다른 사람에게 위험과 장해를 주는 방법으로 운용하여서는 아니 된다.\n",
      "[본조신설 2023. 4. 18.]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 5\n",
      "▶ 페이지 번호 : 17\n",
      "▶ 전체 내용:\n",
      "passage: 법제처                                                            17                                                       국가법령정보센터\n",
      "도로교통법\n",
      "③ 차마의 운전자는 자전거등이 자전거횡단도를 통행하고 있을 때에는 자전거등의 횡단을 방해하거나 위험하게 하\n",
      "지 아니하도록 그 자전거횡단도 앞(정지선이 설치되어 있는 곳에서는 그 정지선을 말한다)에서 일시정지하여야 한\n",
      "다.<개정 2020. 6. 9.>\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제16조(노면전차 전용로의 설치 등) ① 시장등은 교통을 원활하게 하기 위하여 노면전차 전용도로 또는 전용차로를 설\n",
      "치하려는 경우에는 「도시철도법」 제7조제1항에 따른 도시철도사업계획의 승인 전에 다음 각 호의 사항에 대하여 시\n",
      "ㆍ도경찰청장과 협의하여야 한다. 사업 계획을 변경하려는 경우에도 또한 같다. <개정 2020. 12. 22.>\n",
      "1. 노면전차의 설치 방법 및 구간\n",
      "2. 노면전차 전용로 내 교통안전시설의 설치\n",
      "3. 그 밖에 노면전차 전용로의 관리에 관한 사항\n",
      "② 노면전차의 운전자는 제1항에 따른 노면전차 전용도로 또는 전용차로로 통행하여야 하며, 차마의 운전자는 노면\n",
      "전차 전용도로 또는 전용차로를 다음 각 호의 경우를 제외하고는 통행하여서는 아니 된다.\n",
      "1. 좌회전, 우회전, 횡단 또는 회전하기 위하여 궤도부지를 가로지르는 경우\n",
      "2. 도로, 교통안전시설, 도로의 부속물 등의 보수를 위하여 진입이 불가피한 경우\n",
      "3. 노면전차 전용차로에서 긴급자동차가 그 본래의 긴급한 용도로 운행되고 있는 경우\n",
      "[본조신설 2018. 3. 27.]\n",
      " \n",
      "제17조(자동차등과 노면전차의 속도) ① 자동차등(개인형 이동장치는 제외한다. 이하 이 조에서 같다)과 노면전차의 도\n",
      "로 통행 속도는 행정안전부령으로 정한다. <개정 2013. 3. 23., 2014. 11. 19., 2017. 7. 26., 2018. 3. 27., 2020. 6. 9.>\n",
      "② 경찰청장이나 시ㆍ도경찰청장은 도로에서 일어나는 위험을 방지하고 교통의 안전과 원활한 소통을 확보하기 위\n",
      "하여 필요하다고 인정하는 경우에는 다음 각 호의 구분에 따라 구역이나 구간을 지정하여 제1항에 따라 정한 속도\n",
      "를 제한할 수 있다.<개정 2020. 12. 22.>\n",
      "1. 경찰청장: 고속도로\n",
      "2. 시ㆍ도경찰청장: 고속도로를\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 6\n",
      "▶ 페이지 번호 : 9\n",
      "▶ 전체 내용:\n",
      "passage: 제외한다)\n",
      "바. 「청소년활동 진흥법」에 따른 청소년수련시설\n",
      "사. 「장애인복지법」에 따른 장애인복지시설(장애인 직업재활시설은 제외한다)\n",
      "아. 「도서관법」에 따른 공공도서관\n",
      "자. 「평생교육법」에 따른 시ㆍ도평생교육진흥원 및 시ㆍ군ㆍ구평생학습관\n",
      "차. 「사회복지사업법」에 따른 사회복지시설 및 사회복지관\n",
      "24. “주차”란 운전자가 승객을 기다리거나 화물을 싣거나 차가 고장 나거나 그 밖의 사유로 차를 계속 정지 상태에\n",
      "두는 것 또는 운전자가 차에서 떠나서 즉시 그 차를 운전할 수 없는 상태에 두는 것을 말한다.\n",
      "25. “정차”란 운전자가 5분을 초과하지 아니하고 차를 정지시키는 것으로서 주차 외의 정지 상태를 말한다.\n",
      "26. “운전”이란 도로(제27조제6항제3호ㆍ제44조ㆍ제45조ㆍ제54조제1항ㆍ제148조ㆍ제148조의2 및 제156조제10호\n",
      "의 경우에는 도로 외의 곳을 포함한다)에서 차마 또는 노면전차를 그 본래의 사용방법에 따라 사용하는 것(조종\n",
      "또는 자율주행시스템을 사용하는 것을 포함한다)을 말한다.\n",
      "27. “초보운전자”란 처음 운전면허를 받은 날(처음 운전면허를 받은 날부터 2년이 지나기 전에 운전면허의 취소처분\n",
      "을 받은 경우에는 그 후 다시 운전면허를 받은 날을 말한다)부터 2년이 지나지 아니한 사람을 말한다. 이 경우 원\n",
      "동기장치자전거면허만 받은 사람이 원동기장치자전거면허 외의 운전면허를 받은 경우에는 처음 운전면허를 받\n",
      "은 것으로 본다.\n",
      "28. “서행”(徐行)이란 운전자가 차 또는 노면전차를 즉시 정지시킬 수 있는 정도의 느린 속도로 진행하는 것을 말한\n",
      "다.\n",
      "29. “앞지르기”란 차의 운전자가 앞서가는 다른 차의 옆을 지나서 그 차의 앞으로 나가는 것을 말한다.\n",
      "30. “일시정지”란 차 또는 노면전차의 운전자가 그 차 또는 노면전차의 바퀴를 일시적으로 완전히 정지시키는 것을\n",
      "말한다.\n",
      "31. “보행자전용도로”란 보행자만 다닐 수 있도록 안전표지나 그와 비슷한 인공구조물로 표시한 도로를 말한다.\n",
      "31의2. “보행자우선도로”란 「보행안전 및 편의증진에 관한 법률」 제2조제3호에 따른 보행자우선도로를 말한다.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 7\n",
      "▶ 페이지 번호 : 22\n",
      "▶ 전체 내용:\n",
      "passage: 법제처                                                            22                                                       국가법령정보센터\n",
      "도로교통법\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제32조(정차 및 주차의 금지) 모든 차의 운전자는 다음 각 호의 어느 하나에 해당하는 곳에서는 차를 정차하거나 주차\n",
      "하여서는 아니 된다. 다만, 이 법이나 이 법에 따른 명령 또는 경찰공무원의 지시를 따르는 경우와 위험방지를 위하\n",
      "여 일시정지하는 경우에는 그러하지 아니하다. <개정 2018. 2. 9., 2020. 10. 20., 2020. 12. 22., 2021. 11. 30.>\n",
      "1. 교차로ㆍ횡단보도ㆍ건널목이나 보도와 차도가 구분된 도로의 보도(「주차장법」에 따라 차도와 보도에 걸쳐서 설\n",
      "치된 노상주차장은 제외한다)\n",
      "2. 교차로의 가장자리나 도로의 모퉁이로부터 5미터 이내인 곳\n",
      "3. 안전지대가 설치된 도로에서는 그 안전지대의 사방으로부터 각각 10미터 이내인 곳\n",
      "4. 버스여객자동차의 정류지(停留地)임을 표시하는 기둥이나 표지판 또는 선이 설치된 곳으로부터 10미터 이내인\n",
      "곳. 다만, 버스여객자동차의 운전자가 그 버스여객자동차의 운행시간 중에 운행노선에 따르는 정류장에서 승객을\n",
      "태우거나 내리기 위하여 차를 정차하거나 주차하는 경우에는 그러하지 아니하다.\n",
      "5. 건널목의 가장자리 또는 횡단보도로부터 10미터 이내인 곳\n",
      "6. 다음 각 목의 곳으로부터 5미터 이내인 곳\n",
      "가. 「소방기본법」 제10조에 따른 소방용수시설 또는 비상소화장치가 설치된 곳\n",
      "나. 「소방시설 설치 및 관리에 관한 법률」 제2조제1항제1호에 따른 소방시설로서 대통령령으로 정하는 시설이\n",
      "설치된 곳\n",
      "7. 시ㆍ도경찰청장이 도로에서의 위험을 방지하고 교통의 안전과 원활한 소통을 확보하기 위하여 필요하다고 인정\n",
      "하여 지정한 곳\n",
      "8. 시장등이 제12조제1항에 따라 지정한 어린이 보호구역\n",
      "[전문개정 2011. 6. 8.]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 8\n",
      "▶ 페이지 번호 : 7\n",
      "▶ 전체 내용:\n",
      "passage: 제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 도로에서 일어나는 교통상의 모든 위험과 장해를 방지하고 제거하여 안전하고 원활한 교통을 확보\n",
      "함을 목적으로 한다.\n",
      " \n",
      "제2조(정의) 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2012. 3. 21., 2013. 3. 23., 2014. 1. 28., 2014. 11. 19.,\n",
      "2017. 3. 21., 2017. 7. 26., 2017. 10. 24., 2018. 3. 27., 2020. 5. 26., 2020. 6. 9., 2020. 12. 22., 2021. 10. 19., 2022. 1.\n",
      "11., 2023. 4. 18., 2023. 10. 24.>\n",
      "1. “도로”란 다음 각 목에 해당하는 곳을 말한다.\n",
      "가. 「도로법」에 따른 도로\n",
      "나. 「유료도로법」에 따른 유료도로\n",
      "다. 「농어촌도로 정비법」에 따른 농어촌도로\n",
      "라. 그 밖에 현실적으로 불특정 다수의 사람 또는 차마(車馬)가 통행할 수 있도록 공개된 장소로서 안전하고 원활\n",
      "한 교통을 확보할 필요가 있는 장소\n",
      "2. “자동차전용도로”란 자동차만 다닐 수 있도록 설치된 도로를 말한다.\n",
      "3. “고속도로”란 자동차의 고속 운행에만 사용하기 위하여 지정된 도로를 말한다.\n",
      "4. “차도”(車道)란 연석선(차도와 보도를 구분하는 돌 등으로 이어진 선을 말한다. 이하 같다), 안전표지 또는 그와 비\n",
      "슷한 인공구조물을 이용하여 경계(境界)를 표시하여 모든 차가 통행할 수 있도록 설치된 도로의 부분을 말한다.\n",
      "5. “중앙선”이란 차마의 통행 방향을 명확하게 구분하기 위하여 도로에 황색 실선(實線)이나 황색 점선 등의 안전표\n",
      "지로 표시한 선 또는 중앙분리대나 울타리 등으로 설치한 시설물을 말한다. 다만, 제14조제1항 후단에 따라 가변\n",
      "차로(可變車路)가 설치된 경우에는 신호기가 지시하는 진행방향의 가장 왼쪽에 있는 황색 점선을 말한다.\n",
      "6. “차로”란 차마가 한 줄로 도로의 정하여진 부분을 통행하도록 차선(車線)으로 구분한 차도의 부분을 말한다.\n",
      "7. “차선”이란 차로와 차로를 구분하기 위하여 그 경계지점을 안전표지로 표시한 선을 말한다.\n",
      "7의2. “노면전차 전용로”란 도로에서 궤도를 설치하고, 안전표지 또는 인공구조물로 경계를 표시하여 설치한 「도시\n",
      "철도법」 제18조의2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 9\n",
      "▶ 페이지 번호 : 15\n",
      "▶ 전체 내용:\n",
      "passage: 제외한다)의 운전자는 안전표지로 통행이 허용된 장소를 제외하고는 자전거도로 또는 길가장자\n",
      "리구역으로 통행하여서는 아니 된다. 다만, 「자전거 이용 활성화에 관한 법률」 제3조제4호에 따른 자전거 우선도로\n",
      "의 경우에는 그러하지 아니하다.<개정 2014. 1. 28., 2020. 6. 9.>\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제13조의2(자전거등의 통행방법의 특례) ① 자전거등의 운전자는 자전거도로(제15조제1항에 따라 자전거만 통행할 수\n",
      "있도록 설치된 전용차로를 포함한다. 이하 이 조에서 같다)가 따로 있는 곳에서는 그 자전거도로로 통행하여야 한다.\n",
      "<개정 2020. 6. 9.>\n",
      "② 자전거등의 운전자는 자전거도로가 설치되지 아니한 곳에서는 도로 우측 가장자리에 붙어서 통행하여야 한다.\n",
      "<개정 2020. 6. 9.>\n",
      "③ 자전거등의 운전자는 길가장자리구역(안전표지로 자전거등의 통행을 금지한 구간은 제외한다)을 통행할 수 있다\n",
      ". 이 경우 자전거등의 운전자는 보행자의 통행에 방해가 될 때에는 서행하거나 일시정지하여야 한다.<개정 2020. 6.\n",
      "9.>\n",
      "④ 자전거등의 운전자는 제1항 및 제13조제1항에도 불구하고 다음 각 호의 어느 하나에 해당하는 경우에는 보도를\n",
      "통행할 수 있다. 이 경우 자전거등의 운전자는 보도 중앙으로부터 차도 쪽 또는 안전표지로 지정된 곳으로 서행하여\n",
      "야 하며, 보행자의 통행에 방해가 될 때에는 일시정지하여야 한다.<개정 2013. 3. 23., 2014. 11. 19., 2017. 7. 26.,\n",
      "2018. 3. 27., 2020. 6. 9.>\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 문서 10\n",
      "▶ 페이지 번호 : 11\n",
      "▶ 전체 내용:\n",
      "passage: 제5조의2에 따라 설립된 모범운전자연합회의 사업에 필요한 보조금을 지원할\n",
      "수 있다.<신설 2016. 1. 27.>\n",
      "[본조신설 2012. 3. 21.]\n",
      " \n",
      "제6조(통행의 금지 및 제한) ① 시ㆍ도경찰청장은 도로에서의 위험을 방지하고 교통의 안전과 원활한 소통을 확보하기\n",
      "위하여 필요하다고 인정할 때에는 구간(區間)을 정하여 보행자, 차마 또는 노면전차의 통행을 금지하거나 제한할 수\n",
      "있다. 이 경우 시ㆍ도경찰청장은 보행자, 차마 또는 노면전차의 통행을 금지하거나 제한한 도로의 관리청에 그 사실\n",
      "을 알려야 한다. <개정 2018. 3. 27., 2020. 12. 22.>\n",
      "② 경찰서장은 도로에서의 위험을 방지하고 교통의 안전과 원활한 소통을 확보하기 위하여 필요하다고 인정할 때\n",
      "에는 우선 보행자, 차마 또는 노면전차의 통행을 금지하거나 제한한 후 그 도로관리자와 협의하여 금지 또는 제한의\n",
      "대상과 구간 및 기간을 정하여 도로의 통행을 금지하거나 제한할 수 있다.<개정 2018. 3. 27.>\n",
      "③ 시ㆍ도경찰청장이나 경찰서장은 제1항이나 제2항에 따른 금지 또는 제한을 하려는 경우에는 행정안전부령으로\n",
      "정하는 바에 따라 그 사실을 공고하여야 한다.<개정 2013. 3. 23., 2014. 11. 19., 2017. 7. 26., 2020. 12. 22.>\n",
      "④ 경찰공무원은 도로의 파손, 화재의 발생이나 그 밖의 사정으로 인한 도로에서의 위험을 방지하기 위하여 긴급히\n",
      "조치할 필요가 있을 때에는 필요한 범위에서 보행자, 차마 또는 노면전차의 통행을 일시 금지하거나 제한할 수 있다\n",
      ".<개정 2018. 3. 27.>\n",
      "[전문개정 2011. 6. 8.]\n",
      " \n",
      "제7조(교통 혼잡을 완화시키기 위한 조치) 경찰공무원은 보행자, 차마 또는 노면전차의 통행이 밀려서 교통 혼잡이 뚜\n",
      "렷하게 우려될 때에는 혼잡을 덜기 위하여 필요한 조치를 할 수 있다. <개정 2018. 3. 27.>\n",
      "[전문개정 2011. 6. 8.]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ===== 1. 라이브러리 임포트 =====\n",
    "import os\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 모든 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ✅ 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ===== 캐시 저장 경로 =====\n",
    "VECTORSTORE_PATH = \"./vectorstore_cache\"\n",
    "\n",
    "# ===== 2. PDF 로드 (첫 실행 시에만) =====\n",
    "pdf_path = r\"도로교통법(법률)(제20677호).pdf\"\n",
    "\n",
    "# ===== 4. 임베딩 모델 =====\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\"device\": \"cuda\"},  #if torch.cuda.is_available() else \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "\n",
    "# ===== 5. 벡터스토어 로드 또는 생성 =====\n",
    "if os.path.exists(VECTORSTORE_PATH):\n",
    "    print(\"✅ 기존 벡터스토어 로드 중...\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VECTORSTORE_PATH,\n",
    "        embedding,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    print(\"⚡ 신규 벡터스토어 생성 중...\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "\n",
    "    # 문서 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"제\", \"조\", \"\\n\\n\", \"\\n\"],\n",
    "        chunk_size=1200,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "\n",
    "    # E5 권장 프리픽스 적용\n",
    "    splits_e5 = [\n",
    "        Document(page_content=\"passage: \" + d.page_content, metadata=d.metadata)\n",
    "        for d in splits\n",
    "    ]\n",
    "\n",
    "    # FAISS 인덱스 생성\n",
    "    vectorstore = FAISS.from_documents(splits_e5, embedding)\n",
    "\n",
    "    # 로컬 저장\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "    print(f\"💾 벡터스토어 저장 완료: {VECTORSTORE_PATH}\")\n",
    "\n",
    "# ===== 6. 리트리버 설정 =====\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 10, \"fetch_k\": 20}\n",
    ")\n",
    "\n",
    "# ===== 7. 질문(Query) =====\n",
    "query = \"\"\"\n",
    "\n",
    "에고 차량은 3차선 도로의 중간 차선을 주행합니다. \n",
    "에고 차량이 차선을 바꿔 버스 전용차로로 주행합니다.\n",
    "보행자가 갑자기 무단횡단하여 버스 전용차로 도로로 들어서고, 자아 차량과 보행자 간의 충돌이 발생합니다. \n",
    "보행자가 바닥에 쓰러지고 에고 차량은 주행을 멈춥니다.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ===== 8. 관련 문서 검색 =====\n",
    "search_result = retriever.get_relevant_documents(f\"query: {query.strip()}\")\n",
    "\n",
    "# ===== 9. 검색 결과 미리보기 =====\n",
    "def pretty_print_documents(doc_list):\n",
    "    for i, doc in enumerate(doc_list):\n",
    "        print(f\"\\n📄 문서 {i+1}\")\n",
    "        print(f\"▶ 페이지 번호 : {doc.metadata.get('page_label', doc.metadata.get('page'))}\")\n",
    "        print(\"▶ 전체 내용:\")\n",
    "        print(doc.page_content)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "pretty_print_documents(search_result)\n",
    "\n",
    "# ===== 10. LLM 모델 =====\n",
    "llm = Ollama(model=\"gpt-oss\")\n",
    "\n",
    "# ===== 11. 프롬프트 템플릿 =====\n",
    "template = \"\"\"\n",
    "당신은 도로교통법 전문가입니다.\n",
    "다음은 도로교통법 문서에서 검색된 일부 조항과 문장입니다:\n",
    "\n",
    "{context}\n",
    "\n",
    "아래 도로주행상황설명 텍스트에 대해 도로교통법 조문을 인용해 객관식 문제를 생성하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 도로주행상황설명 텍스트는 영상을 시간순으로 보며 운전자 시점에서 벌어지는 상황을 나열한 것입니다. 운전자 시점에서 상황을 이해하세요.\n",
    "2. 도로 주행 시 운전자가 마주하는 사고 위험 순간이 있습니다. 사고 위험 순간을 리스트로 정리해주세요.\n",
    "3. 사고 위험 순간 리스트의 케이스를 중 하나를 골라, 만약 문제를 푸는 사람이 운전자라면 사고 위험 순간 직전에 어떻게 행동하는 것이 올바른 행동인지 맞추는 객관식 문제를 만들어주세요.\n",
    "4. 객관식 문제의 선택지는 정답(운전자의 올바른 행동) 1개, 오답(운전자의 잘못된 행동) 3개로 만들어주세요.\n",
    "5. 운전자의 올바른 행동은 도로교통법 조문에 근거한 행동이어야 합니다. 운전자의 잘못된 행동은 위법,위협,사고유발 행동이어야 합니다.\n",
    "6. 문제와 답을 만든 후, 4개의 선택지에 대해 해설을 해주세요. \n",
    "7. 정답 선지의 경우, 왜 정답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 정답인 이유를 설명하세요.\n",
    "8. 오답 선지의 경우, 왜 오답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 오답인 이유를 설명하세요.\n",
    "9. 위 작업을 사고 위험 순간 리스트에 있는 모든 케이스에 대해 적용해주세요. 케이스 1개 당 객관식 문제 1개를 만들어주세요. 만약 케이스가 8개라면 객관식 문제 8개가 나와야 합니다.\n",
    "10. 답변은 한국어로 해주세요.\n",
    "11. 위 요구사항을 전부 지켜주세요.\n",
    "\n",
    "\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ===== 12. 최종 프롬프트 생성 =====\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in search_result)\n",
    "final_prompt = prompt.format(context=context, question=query)\n",
    "\n",
    "# ===== 13. Ollama 호출 =====\n",
    "response = llm.invoke(final_prompt)\n",
    "\n",
    "print(f\"\\n\\n======= Ollama 모델 : {llm.model} 응답 =======\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8922923",
   "metadata": {},
   "source": [
    "### 상황 하나 당 문제 1개\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f678e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1. 라이브러리 임포트 =====\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pprint import pprint\n",
    "from langchain.schema import Document\n",
    "import torch\n",
    "# 모든 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # 모든 경고 무시\n",
    "\n",
    "\n",
    "# ✅ 디바이스 설정: GPU 사용 가능하면 GPU, 아니면 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# ===== 2. PDF 문서 로드 =====\n",
    "## PyPDFLoader가 PDF를 페이지 단위 Document 리스트로 로딩\n",
    "## 각 Document에는 page_content(텍스트)와 metadata(페이지 번호 등)가 포함\n",
    "## page_label이 있으면 그걸, 없으면 page를 써서 나중에 페이지 추적 \n",
    "loader = PyPDFLoader(r\"C:\\Users\\Admin\\Desktop\\RAG\\RAG\\도로교통법(법률)(제20677호).pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "# ===== 3. 문서 분할 (Chunk 최적화) =====\n",
    "## chunk 크기를 800자로 늘리고, 100자 겹치게 설정하여 문맥 손실을 최소화 => 조항 중 글자 수 가장 긴 거 테스트!!!!!!!!!!!!!!\n",
    "## separators=[\"제\", \"조\", \"\\n\\n\", \"\\n\"] : 한국어 법령 형식을 고려해 “제…조…” 경계와 줄바꿈 기준으로 최대한 의미 단위로 쪼개려는 의도\n",
    "## chunk_size=800, chunk_overlap=100 : 800자 청크에 100자 겹침으로 문맥 손실을 줄입니다.\n",
    "## 결과: 검색 단위가 될 splits 리스트 생성.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"제\", \"조\", \"\\n\\n\", \"\\n\"], \n",
    "    chunk_size=800, \n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(pages)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===== 4. 임베딩 (다국어 E5) ===== ==> 임베딩 한 결과물 저장해놓고 로드해서 사용하는 방향으로 (시간 단축)!!!!!!!!!!!!!!!!!!!!!\n",
    "## 모델: intfloat/multilingual-e5-base (E5)\n",
    "## 프리픽스 컨벤션을 쓰는 게 포인트:\n",
    "## 문서/패시지 쪽엔 \"passage: ...\", 쿼리엔 \"query: ...\".\n",
    "\n",
    "# pdf를 vetor화 해서 그 값을 로컬에 저장해놔라.\n",
    "# pdf를 청킹단위로 veterdb에 저장. metadata를 잘 쓰는 게\n",
    "# 같은 임베딩 모델로 vetordb에서 찾아야 잘 찾아준다. vetor화 한 방식이 다 다르기 때문\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "## encode_kwargs={\"normalize_embeddings\": True}\n",
    "## 임베딩을 정규화(단위 벡터)하여 코사인 유사도와 동일하게 취급\n",
    "## FAISS의 기본 L2 거리도, 단위 벡터라면 사실상 코사인과 등가\n",
    "## 왜 E5 + “query:/passage:”가 중요한가?\n",
    "### E5는 “dual-encoder(질의/문서) 용도”로 학습되어 프리픽스로 역할을 명확히 해주면 검색 품질이 좋아집니다.\n",
    "### normalize_embeddings=True로 코사인 기반 랭킹이 안정화 → FAISS L2와 정합.\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # 코사인 유사도 안정화 \n",
    "    # 유사도 종류도 여러개..!!!!!!!!!!!!\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ===== 5. 인덱스 (문서에 passage) =====\n",
    "## splits_e5 = [Document(page_content=\"passage: \" + d.page_content, ...)] : E5 권장 프리픽스 적용 후 인덱싱.\n",
    "## FAISS.from_documents(splits_e5, embedding) -> 각 청크를 임베딩 → FAISS 인덱스에 저장.\n",
    "## retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10, \"fetch_k\": 20})\n",
    "### MMR(Maximal Marginal Relevance) 리트리버:\n",
    "### 단순 유사도 Top-K와 달리 다양성을 고려해 중복/유사 청크를 줄이고 대표성을 높입니다.\n",
    "### fetch_k=20개를 먼저 후보로 뽑고, 그중 상호 중복을 줄이면서 k=10개를 최종 반환.\n",
    "\n",
    "splits_e5 = [Document(page_content=\"passage: \" + d.page_content, metadata=d.metadata) for d in splits]\n",
    "vectorstore = FAISS.from_documents(splits_e5, embedding) \n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10, \"fetch_k\": 20}) # ranking\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
    "## 검색 시 유사도로 할지, 키워드로 할지 정해야 => 상의 필요\n",
    "### 키워드 검색이 필요 없다면 faiss (유사도 기반, 무료)\n",
    "### 키워드 검색 시 : 파서 중요. 형태소 기반 문서 인덱싱\n",
    "### 각각의 장점을 가져오기 위해 앙상블 리트리버(가중치 조절로) => 테스트 필요\n",
    "### 키워드 + 유사도 => 가중치 설정해서 ranking -> retriever 검색\n",
    "### 결과물 ranking\n",
    "\n",
    "\n",
    "# ===== 7. 질문(Query) 확장 =====\n",
    "query = \"\"\"\n",
    "\n",
    "The ego vehicle drives in the middle lane of a four-lane road under clear weather. It approaches a bus stop where a pedestrian is walking across the road. The pedestrian suddenly steps onto the road, and the ego vehicle fails to stop in time, causing a collision. The pedestrian is knocked to the ground, and the vehicle continues forward after the impact.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ===== 8. 관련 문서 검색 (쿼리에 query) =====a\n",
    "search_result = retriever.get_relevant_documents(f\"query: {query.strip()}\")\n",
    "\n",
    "\n",
    "\n",
    "# ===== 9. 검색 결과 미리보기 =====\n",
    "def pretty_print_documents(doc_list):\n",
    "    for i, doc in enumerate(doc_list):\n",
    "        print(f\"\\n📄 문서 {i+1}\")\n",
    "        print(f\"▶ 페이지 번호 : {doc.metadata.get('page_label', doc.metadata.get('page'))}\")\n",
    "        print(\"▶ 전체 내용:\")\n",
    "        print(doc.page_content)  # 전문 출력\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "pretty_print_documents(search_result)\n",
    "\n",
    "\n",
    "\n",
    "# ===== 10. LLM 모델 (Ollama) =====\n",
    "llm = Ollama(model=\"gpt-oss\")\n",
    "\n",
    "\n",
    "# ===== 11. 프롬프트 템플릿 =====\n",
    "## 마크다운 문법 사용 가능함. xml을 태그로 줄 수 있음\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 도로교통법 전문가입니다.\n",
    "다음은 도로교통법 문서에서 검색된 일부 조항과 문장입니다:\n",
    "\n",
    "{context}\n",
    "\n",
    "아래 도로주행상황설명 텍스트에 대해 도로교통법 조문을 인용해 객관식 문제를 생성하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 도로주행상황설명 텍스트는 영상을 시간순으로 보며 운전자 시점에서 벌어지는 상황을 나열한 것입니다. 운전자 시점에서 상황을 이해하세요.\n",
    "2. 도로 주행 시 운전자가 마주하는 사고 위험 순간이 있습니다. 사고 위험 순간을 리스트로 정리해주세요.\n",
    "3. 사고 위험 순간 리스트의 케이스를 중 하나를 골라, 만약 문제를 푸는 사람이 운전자라면 사고 위험 순간 직전에 어떻게 행동하는 것이 올바른 행동인지 맞추는 객관식 문제를 만들어주세요.\n",
    "4. 객관식 문제의 선택지는 정답(운전자의 올바른 행동) 1개, 오답(운전자의 잘못된 행동) 3개로 만들어주세요.\n",
    "5. 운전자의 올바른 행동은 도로교통법 조문에 근거한 행동이어야 합니다. 운전자의 잘못된 행동은 위법,위협,사고유발 행동이어야 합니다.\n",
    "6. 문제와 답을 만든 후, 4개의 선택지에 대해 해설을 해주세요. \n",
    "7. 정답 선지의 경우, 왜 정답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 정답인 이유를 설명하세요.\n",
    "8. 오답 선지의 경우, 왜 오답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 오답인 이유를 설명하세요.\n",
    "9. 위 작업을 사고 위험 순간 리스트에 있는 모든 케이스에 대해 적용해주세요. 케이스 1개 당 객관식 문제 1개를 만들어주세요. 만약 케이스가 8개라면 객관식 문제 8개가 나와야 합니다.\n",
    "10. 위 요구사항을 전부 지켜주세요.\n",
    "\n",
    "\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# ===== 12. 최종 프롬프트 생성 =====\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in search_result)\n",
    "final_prompt = prompt.format(context=context, question=query)\n",
    "print(\"\\n\\n======= 도로주행설명 텍스트 =======\")\n",
    "print(query.replace(\".\",\".\\n\"))  # 최종 프롬프트 출력\n",
    "\n",
    "\n",
    "# ===== 13. Ollama 호출 =====\n",
    "response = llm.invoke(final_prompt) # temperature 등등 조절하면서 테스트\n",
    "## 검색된 법령 문구를 그대로 컨텍스트로 넣었기 때문에 인용 정확도가 올라감\n",
    "## \n",
    "\n",
    "\n",
    "# 모델명을 llm 객체의 속성에서 가져오도록 수정\n",
    "print(f\"\\n\\n======= Ollama 모델 : {llm.model} 응답 =======\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612490dc",
   "metadata": {},
   "source": [
    "# 로직 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ce962",
   "metadata": {},
   "source": [
    "## 로직 A (위험상황→RAG 일괄 수집→문제+해설)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2544e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# logic_a.py\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===== 경로/설정 =====\n",
    "VECTORSTORE_PATH = \"./vectorstore_cache\"\n",
    "PDF_PATH = r\"도로교통법(법률)(제20677호).pdf\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# ===== 임베딩 =====\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# ===== 벡터스토어 =====\n",
    "if os.path.exists(VECTORSTORE_PATH):\n",
    "    print(\"✅ 기존 벡터스토어 로드 중...\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VECTORSTORE_PATH, embedding, allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    print(\"⚡ 신규 벡터스토어 생성 중...\")\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    pages = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"제\", \"조\", \"\\n\\n\", \"\\n\"],\n",
    "        chunk_size=1200,\n",
    "        chunk_overlap=200,\n",
    "    )\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "\n",
    "    # E5 권장 프리픽스\n",
    "    splits_e5 = [\n",
    "        Document(page_content=\"passage: \" + d.page_content, metadata=d.metadata)\n",
    "        for d in splits\n",
    "    ]\n",
    "\n",
    "    vectorstore = FAISS.from_documents(splits_e5, embedding)\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "    print(f\"💾 벡터스토어 저장 완료: {VECTORSTORE_PATH}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 6, \"fetch_k\": 20}\n",
    ")\n",
    "\n",
    "# ===== LLM =====\n",
    "llm = Ollama(model=\"gpt-oss\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 헬퍼\n",
    "# =========================\n",
    "def extract_dangers_from_query(query: str) -> list[str]:\n",
    "    \"\"\"gpt-oss로 사고 위험 상황 리스트(JSON 배열) 추출\"\"\"\n",
    "    template = \"\"\"\n",
    "당신은 도로교통법 기반 사고 위험 분석가입니다.\n",
    "아래 도로주행상황설명 텍스트에서 운전자 시점의 '사고 위험 순간'만 핵심 키워드 중심으로 1~8개 목록으로 뽑아주세요.\n",
    "- 시간순\n",
    "- 출력은 문자열 리스트만\n",
    "\n",
    "텍스트:\n",
    "{query}\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate.from_template(template).format(query=query.strip())\n",
    "    raw = llm.invoke(prompt)\n",
    "\n",
    "    import json, re\n",
    "    try:\n",
    "        match = re.search(r\"\\[.*\\]\", str(raw), flags=re.S)\n",
    "        arr = json.loads(match.group(0)) if match else []\n",
    "        return [str(x).strip() for x in arr if str(x).strip()]\n",
    "    except Exception:\n",
    "        lines = [l.strip(\"-• \\n\\r\\t\") for l in str(raw).splitlines() if l.strip()]\n",
    "        return [l for l in lines if len(l) > 1][:6]\n",
    "\n",
    "\n",
    "def retrieve_law_context_for_items(items: list[str], top_k_per_item: int = 3) -> list[Document]:\n",
    "    \"\"\"각 항목으로 RAG하고 문서 합침(중복 제거)\"\"\"\n",
    "    seen = set()\n",
    "    merged_docs: list[Document] = []\n",
    "    for it in items:\n",
    "        q = f\"query: {it}\"\n",
    "        docs = retriever.get_relevant_documents(q)[:top_k_per_item]\n",
    "        for d in docs:\n",
    "            key = (d.metadata.get(\"page_label\", d.metadata.get(\"page\")), d.page_content[:100])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                merged_docs.append(d)\n",
    "    return merged_docs\n",
    "\n",
    "\n",
    "def join_docs(docs: list[Document]) -> str:\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page_label\", d.metadata.get(\"page\"))\n",
    "        parts.append(f\"[페이지 {page}]\\n{d.page_content}\")\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Logic A 본체\n",
    "# =========================\n",
    "def run_logic_a(query: str):\n",
    "    dangers = extract_dangers_from_query(query)\n",
    "    print(\"🔎 추출된 사고 위험 상황:\")\n",
    "    pprint(dangers)\n",
    "\n",
    "    if not dangers:\n",
    "        print(\"⚠️ 위험 상황을 추출하지 못했습니다.\")\n",
    "        return\n",
    "\n",
    "    law_docs = retrieve_law_context_for_items(dangers, top_k_per_item=3)\n",
    "    context = join_docs(law_docs)\n",
    "\n",
    "    template = \"\"\"\n",
    "당신은 도로교통법 전문가입니다.\n",
    "\n",
    "# 법령 발췌(context)\n",
    "{context}\n",
    "\n",
    "# 사고 위험 순간 목록(dangers)\n",
    "{dangers}\n",
    "\n",
    "요구사항:\n",
    "1) dangers의 각 항목(사고 위험 순간)마다 객관식 문제 1개를 만드세요.\n",
    "2) 각 문제: 보기 4개(정답 1, 오답 3). 운전자 시점에서 '사고 위험 직전 올바른 행동'을 맞히는 문제.\n",
    "3) 정답/오답 해설에는 반드시 위 context에 포함된 '도로교통법 제XX조 제X항 \"문장 전체\"'를 그대로 인용하고, 근거로 왜 정/오답인지 설명.\n",
    "4) 한국어로 출력. 문제는 1) 2) 3) ... 번호로 구분.\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate.from_template(template).format(\n",
    "        context=context,\n",
    "        dangers=\"\\n\".join(f\"- {d}\" for d in dangers),\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    print(\"\\n\\n======= Logic A 결과 =======\")\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "from logic_a_notebook import run_logic_a\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "The ego vehicle drive down the middle lane of a three-lane road in clear weather. \n",
    "The ego vehicle changes lanes and approaches the bus stop.\n",
    "A pedestrian suddenly jaywalks into the road, and there is a collision between the ego vehicle and the pedestrian. \n",
    "The pedestrian fall to the ground and the ego vehicle stop driving.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result = run_logic_a(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad30b92",
   "metadata": {},
   "source": [
    "## 로직 B (위험상황→문제 생성→문제별 RAG→해설)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33650504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 기존 벡터스토어 로드 중...\n",
      "🔎 추출된 사고 위험 상황:\n",
      "['버스 전용 차로로 차선 변경', '보행자 무단횡단', '충돌 발생']\n",
      "\n",
      "📝 생성된 문제(요약):\n",
      "1. [버스 전용 차로로 차선 변경] 버스 전용 차로로 차선 변경하려는 상황에서 운전자는 어떻게 행동해야 합니까? / 정답: A\n",
      "2. [보행자 무단횡단] 보행자가 무단횡단을 하고 있을 때 운전자는 무엇을 해야 합니까? / 정답: A\n",
      "3. [충돌 발생] 충돌이 발생한 직후 운전자는 무엇을 해야 합니까? / 정답: A\n",
      "[DEBUG] questions 갯수: 3\n",
      "\n",
      "\n",
      "======= Logic B 결과 =======\n",
      "[DEBUG] law_docs 갯수: 5\n",
      "[DEBUG] context 미리보기: [페이지 19] passage: 제2항에도 불구하고 자전거등의 운전자는 교차로에서 좌회전하려는 경우에는 미리 도로의 우측 가장자리로 붙 어 서행하면서 교차로의 가장자리 부분을 이용하여 좌회전하여야 한다.<개정 2020. 6. 9.> ④ 제1항부터 제3항까지의 규정에 따라 우회전이나 좌회전을 하기 위하여 손이나 방향지시기 또는 등화로써 신호 를 하는 차가 있는 경우에 그 뒤차의 운전자는 신호를 한 앞차의 진행을 방해하여서는 아니 된다. ⑤ 모든 차 또는 노면전차의 운전자는 신호기로 교통정리를 하고 있는 교차로에 들어가려는 경우에는 진행하려는 진로의 앞쪽에 있는 차 또는 노면전차의 상황에 따라 교차로(정지선이 설치되어 있는 경우에는 그 정지선을 넘은 부분을 말한다)에 정지하게 되어 다른 차 또는 노면전차의 통행에 방해가 될 우려가 있는 경우에는 그 교차로에 들 어가서는 아니 된다.<개정 2018. 3. 27.> ⑥ 모든 차의 운전자는 교통정리를 하고 있지 아니하고 일시정지나 양보를 표시 ...\n",
      "\n",
      "--- 문제 1 ---\n",
      "[위험상황] 버스 전용 차로로 차선 변경\n",
      "[문제] 버스 전용 차로로 차선 변경하려는 상황에서 운전자는 어떻게 행동해야 합니까?\n",
      "[선택지]\n",
      "A. 현재 차선을 유지하고 버스 전용 차로로 차선 변경을 시도하지 않는다.\n",
      "B. 버스 전용 차로로 차선 변경한다.\n",
      "C. 가속해서 버스 전용 차로를 빠르게 통과한다.\n",
      "D. 신호를 걸어 버스 전용 차로로 이동한다.\n",
      "[정답] A\n",
      "[해설]\n",
      "**정답: A**\n",
      "\n",
      "- **A. 현재 차선을 유지하고 버스 전용 차로로 차선 변경을 시도하지 않는다.**  \n",
      "  도로교통법에 따르면, 전용차로는 ‘전용차로의 설치’에 따라 특정 차량만이 이용할 수 있도록 지정된 차로이며, 그 외 차량은 이용할 수 없다.  \n",
      "  **도로교통법 제15조 제3항 “제2항에 따라 전용차로로 통행할 수 있는 차가 아니면 전용차로로 통행하여서는 아니 된다.”**  \n",
      "  버스 전용 차로는 전용차로에 해당하므로, 운전자가 버스(또는 허가된 차량)가 아니라면 차선 변경을 시도하지 말고 현재 차선을 유지해야 한다. 따라서 선택지 A가 옳다.\n",
      "\n",
      "---\n",
      "\n",
      "**오답선지에 대한 해설**\n",
      "\n",
      "- **B. 버스 전용 차로로 차선 변경한다.**  \n",
      "  도로교통법 제15조 제3항은 “전용차로로 통행할 수 있는 차가 아니면 전용차로로 통행하여서는 아니 된다.”라고 명시하고 있으므로, 허가받지 않은 차량이 버스 전용 차로로 차선 변경을 하면 법에 어긋난다. 따라서 선택지 B는 틀린다.\n",
      "\n",
      "- **C. 가속해서 버스 전용 차로를 빠르게 통과한다.**  \n",
      "  역시 도로교통법 제15조 제3항이 “전용차로로 통행할 수 있는 차가 아니면 전용차로로 통행하여서는 아니 된다.”라고 규정하고 있어, 가속·통과와 같은 행동은 전용차로 이용을 시도하는 것이며 이는 법 위반이다. 따라서 선택지 C는 틀린다.\n",
      "\n",
      "- **D. 신호를 걸어 버스 전용 차로로 이동한다.**  \n",
      "  신호를 걸어 이동하는 행위조차도 전용차로를 이용하려는 시도로 간주되며, 도로교통법 제15조 제3항이 “전용차로로 통행할 수 있는 차가 아니면 전용차로로 통행하여서는 아니 된다.”라고 명시하고 있다. 따라서 선택지 D 역시 법적으로 허용되지 않는 행동이며 틀린다.\n",
      "[DEBUG] law_docs 갯수: 5\n",
      "[DEBUG] context 미리보기: [페이지 17] passage: 제1항에 따라 정한 속도 를 제한할 수 있다.<개정 2020. 12. 22.> 1. 경찰청장: 고속도로 2. 시ㆍ도경찰청장: 고속도로를 제외한 도로 ③ 자동차등과 노면전차의 운전자는 제1항과 제2항에 따른 최고속도보다 빠르게 운전하거나 최저속도보다 느리게 운전하여서는 아니 된다. 다만, 교통이 밀리거나 그 밖의 부득이한 사유로 최저속도보다 느리게 운전할 수밖에 없는 경우에는 그러하지 아니하다.<개정 2018. 3. 27.> [전문개정 2011. 6. 8.] [제목개정 2018. 3. 27.]   제18조(횡단 등의 금지) ① 차마의 운전자는 보행자나 다른 차마의 정상적인 통행을 방해할 우려가 있는 경우에는 차마 를 운전하여 도로를 횡단하거나 유턴 또는 후진하여서는 아니 된다. ② 시ㆍ도경찰청장은 도로에서의 위험을 방지하고 교통의 안전과 원활한 소통을 확보하기 위하여 특히 필요하다고 인정하는 경우에는 도로의 구간을 지정하여 차마의 횡단이나 유턴 또는 후 ...\n",
      "\n",
      "--- 문제 2 ---\n",
      "[위험상황] 보행자 무단횡단\n",
      "[문제] 보행자가 무단횡단을 하고 있을 때 운전자는 무엇을 해야 합니까?\n",
      "[선택지]\n",
      "A. 속도를 줄여 정지하거나 보행자를 보호할 수 있도록 준비한다.\n",
      "B. 정상 속도로 진행한다.\n",
      "C. 가속한다.\n",
      "D. 뒷차를 급제동한다.\n",
      "[정답] A\n",
      "[해설]\n",
      "**정답은 A. “속도를 줄여 정지하거나 보행자를 보호할 수 있도록 준비한다.”**  \n",
      "\n",
      "아래 각 선택지에 대해 도로교통법 조문을 인용하여 정답·오답의 이유를 설명합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### A. “속도를 줄여 정지하거나 보행자를 보호할 수 있도록 준비한다.”  \n",
      "**정답**  \n",
      "도로교통법 제19조 제1항은 “모든 차의 운전자는 같은 방향으로 가고 있는 앞차의 뒤를 따르는 경우에는 앞차가 갑자기 정지하게 되는 경우 그 앞차와의 충돌을 피할 수 있는 필요한 거리를 확보하여야 한다.” 이 조문은 보행자가 무단횡단을 하여 갑자기 정지하거나 전방에 보행자가 나타날 경우 운전자가 필요에 따라 속도를 줄여 정지하거나 사전에 준비(보행자 보호)를 해야 함을 명시하고 있다. 따라서 A가 정답이다.\n",
      "\n",
      "---\n",
      "\n",
      "### B. “정상 속도로 진행한다.”  \n",
      "**오답**  \n",
      "위 조문에서 “필요한 거리를 확보하여야 한다”고 명시하고 있으므로, 정상 속도로 진행하는 것은 충돌 위험을 충분히 방지하지 못할 가능성이 있다. 정상 속도로 계속 진행하면 보행자와의 충돌을 피하기 위한 충분한 제동 거리와 반응 시간을 확보할 수 없으므로, 법적으로 요구되는 ‘필요한 거리 확보’와 부합하지 않는다.  \n",
      "\n",
      "*도로교통법 제19조 제1항 “모든 차의 운전자는 같은 방향으로 가고 있는 앞차의 뒤를 따르는 경우에는 앞차가 갑자기 정지하게 되는 경우 그 앞차와의 충돌을 피할 수 있는 필요한 거리를 확보하여야 한다.”*  \n",
      "\n",
      "---\n",
      "\n",
      "### C. “가속한다.”  \n",
      "**오답**  \n",
      "가속은 앞서 온 보행자와의 충돌 가능성을 높이는 조치이며, ‘필요한 거리 확보’라는 법적 요건을 해치게 된다. 운전자가 가속을 하면 제동 거리가 늘어날 뿐 아니라 보행자와의 충돌을 피하기 위한 시간과 공간이 줄어들게 된다.  \n",
      "\n",
      "*도로교통법 제19조 제1항 “모든 차의 운전자는 같은 방향으로 가고 있는 앞차의 뒤를 따르는 경우에는 앞차가 갑자기 정지하게 되는 경우 그 앞차와의 충돌을 피할 수 있는 필요한 거리를 확보하여야 한다.”*  \n",
      "\n",
      "---\n",
      "\n",
      "### D. “뒷차를 급제동한다.”  \n",
      "**오답**  \n",
      "급제동은 뒤따라 오는 차량과의 충돌 위험을 유발할 수 있다. 제19조는 ‘필요한 거리 확보’라는 최소한의 조치를 요구할 뿐, 급제동을 의무화하거나 권장하지 않는다. 또한 급제동은 무단횡단 보행자와의 충돌을 피하는데 반드시 필요한 조치가 아니며, 차량 간 뒤쪽 충돌 사고의 위험을 증가시키므로 법적 근거가 결여된다.  \n",
      "\n",
      "*도로교통법 제19조 제1항 “모든 차의 운전자는 같은 방향으로 가고 있는 앞차의 뒤를 따르는 경우에는 앞차가 갑자기 정지하게 되는 경우 그 앞차와의 충돌을 피할 수 있는 필요한 거리를 확보하여야 한다.”*  \n",
      "\n",
      "---\n",
      "\n",
      "**요약**  \n",
      "무단횡단을 하고 있는 보행자와의 충돌 방지를 위해서는 운전자는 **속도를 줄여 정지하거나 사전에 보행자를 보호할 수 있도록 준비**해야 한다는 제19조 제1항의 ‘필요한 거리 확보’ 원칙에 따라 행동해야 한다. 정상 속도로 진행하거나 가속, 급제동은 이 원칙을 위반하거나 부적절한 조치이므로 오답이다.\n",
      "[DEBUG] law_docs 갯수: 5\n",
      "[DEBUG] context 미리보기: [페이지 32] passage: 법제처                                                            32                                                       국가법령정보센터 도로교통법 [본조신설 2020. 5. 26.] [법률 제17311호(2020. 5. 26.) 제53조의5의 개정규정은 같은 법 부칙 제2조의 규정에 의하여 2022년 11월 26일까 지 유효함]   제54조(사고발생 시의 조치) ① 차 또는 노면전차의 운전 등 교통으로 인하여 사람을 사상하거나 물건을 손괴(이하 “교 통사고”라 한다)한 경우에는 그 차 또는 노면전차의 운전자나 그 밖의 승무원(이하 “운전자등”이라 한다)은 즉시 정 차하여 다음 각 호의 조치를 하여야 한다. <개정 2014. 1. 28., 2016. 12. 2., 2018. 3. 27.> 1. 사상자를 구호하는 등 필요한 조치 2. 피해자에게 인적 사항(성명ㆍ ...\n",
      "\n",
      "--- 문제 3 ---\n",
      "[위험상황] 충돌 발생\n",
      "[문제] 충돌이 발생한 직후 운전자는 무엇을 해야 합니까?\n",
      "[선택지]\n",
      "A. 즉시 차를 정지시키고, 부상자 여부를 확인한 뒤 119에 연락한다.\n",
      "B. 도로 옆으로 이동하지 않고 계속 운전한다.\n",
      "C. 상대 운전자와 즉시 교환을 시도한다.\n",
      "D. 부상자에게 자가치료를 시도한다.\n",
      "[정답] A\n",
      "[해설]\n",
      "**정답 A**  \n",
      "도로교통법 제54조(사고발생 시의 조치) ① “차 또는 노면전차의 운전 등 교통으로 인하여 사람을 사상하거나 물건을 손괴(이하 “교통사고”라 한다)한 경우에는 그 차 또는 노면전차의 운전자나 그 밖의 승무원(이하 “운전자등”이라 한다)은 즉시 정차하여 다음 각 호의 조치를 하여야 한다.”  \n",
      "이 조문은 사고 직후 “즉시 정차”하고 “사상자를 구호하는 등 필요한 조치”를 해야 한다는 명시적인 규정이므로, 부상자 여부를 확인하고 119에 연락하는 행위가 바로 필요한 조치에 포함됩니다. 따라서 A는 법에 부합합니다.  \n",
      "\n",
      "**오답 B**  \n",
      "도로교통법 제54조 ①에 있는 “즉시 정차하여 다음 각 호의 조치를 하여야 한다”라는 문장은 운전자가 사고 직후 차를 계속 주행해서는 안 된다는 명확한 금지 규정입니다.  \n",
      "따라서 B는 “도로 옆으로 이동하지 않고 계속 운전한다”는 행위가 법에 위반되므로 오답입니다.  \n",
      "\n",
      "**오답 C**  \n",
      "도로교통법 제54조 ②에 “제1항의 경우 그 차 또는 노면전차의 운전자등은 경찰공무원이 현장에 있을 때에는 그 경찰공무원에게… 신고하여야 한다.”라고 명시하고 있습니다.  \n",
      "즉, 사고 발생 시 즉시 교통사고를 신고해야 하며, 상대 운전자와 바로 교환을 시도하는 행위는 법에서 요구하는 절차와 맞지 않으므로 C는 오답입니다.  \n",
      "\n",
      "**오답 D**  \n",
      "도로교통법 제54조 ①에 “사상자를 구호하는 등 필요한 조치”라고 규정하고 있으며, 이는 부상자에게 자가치료를 시도하는 행위가 아닌 부상자에 대한 구호·응급 조치를 의미합니다.  \n",
      "따라서 부상자에게 자가치료를 시도한다는 행위는 법이 요구하는 ‘필요한 조치’에 해당하지 않으므로 D는 오답입니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Jupyter one-cell runner for logic_b\n",
    "# -------------------------------------------------------------\n",
    "# 이 노트북 셀은 \"도로교통법 PDF\"를 벡터화하여 RAG로 참조하고,\n",
    "# 주어진 도로주행 상황 텍스트에서 \"사고 위험 순간\"을 추출한 뒤\n",
    "# 각 위험 상황에 대한 객관식 문제를 생성하고, 법령 문맥을 근거로\n",
    "# 해설을 출력하는 end-to-end 파이프라인입니다.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# 0) 경로/환경 설정\n",
    "# =========================\n",
    "VECTORSTORE_PATH = \"./vectorstore_cache\"  # FAISS 인덱스를 저장/로드할 로컬 폴더\n",
    "PDF_PATH = r\"도로교통법(법률)(제20677호).pdf\"  # 참고할 도로교통법 PDF 경로\n",
    "\n",
    "# CUDA 사용 가능 여부 확인 -> 추론/임베딩 속도에 영향\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# PDF 파일이 실제로 존재하는지 사전 점검(없으면 이후 단계에서 실패)\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"PDF를 찾을 수 없습니다: {PDF_PATH}\\n\"\n",
    "        f\"- 노트북과 같은 폴더에 두거나 PDF_PATH를 수정하세요.\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# 1) 임베딩 모델 준비 (E5)\n",
    "# =========================\n",
    "# - multilingual-e5-base: 도메인 범용 다국어 임베딩 모델\n",
    "# - E5 모델은 입력 텍스트 앞에 'query: ' 또는 'passage: ' 등의 프리픽스를 권장\n",
    "#   (검색 쿼리/문서의 역할을 명확히 하여 검색 품질 향상)\n",
    "# - 현재는 device=\"cuda\"로 고정되어 있어 GPU가 없으면 에러가 날 수 있습니다.\n",
    "#   *CPU만 사용하실 경우* 아래 줄을\n",
    "#     model_kwargs={\"device\": \"cpu\"}\n",
    "#   로 바꾸시길 권장드립니다.\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\"device\": \"cuda\"},  # 필요 시 \"cpu\" 또는 (torch.cuda.is_available() 조건부)로 변경 권장\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # 벡터 정규화(코사인 유사도에 유리)\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) 벡터스토어(FAISS) 로드 또는 신규 생성\n",
    "# =========================\n",
    "# - 최초 실행: PDF를 페이지 단위로 로드 → 텍스트 분할 → 임베딩 → FAISS 생성/저장\n",
    "# - 재실행: 저장된 벡터스토어를 즉시 로드(빠름)\n",
    "if os.path.exists(VECTORSTORE_PATH):\n",
    "    print(\"✅ 기존 벡터스토어 로드 중...\")\n",
    "    # allow_dangerous_deserialization=True:\n",
    "    #  - 로컬에서 신뢰 가능한 환경이라 가정하고, FAISS 인덱스 역직렬화를 허용\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VECTORSTORE_PATH, embedding, allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    print(\"⚡ 신규 벡터스토어 생성 중...\")\n",
    "    # 2-1) PDF 로드(페이지 단위로 Document 리스트 생성)\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    pages = loader.load()\n",
    "\n",
    "    # 2-2) 텍스트 분할\n",
    "    # - '제', '조' 등의 구분자를 우선 고려하여 조항 단위로 쪼개되\n",
    "    #   chunk_size/overlap을 조정해 검색/인용 품질을 튜닝\n",
    "    # - chunk_size가 너무 크면 정확히 필요한 한 문장을 집어오기 어렵고,\n",
    "    #   너무 작으면 문맥이 끊겨 해설 근거가 빈약해질 수 있습니다.\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"제\", \"조\", \"\\n\\n\", \"\\n\"],\n",
    "        chunk_size=1500,     # 기본 1500자\n",
    "        chunk_overlap=200,   # 인접 청크 간 200자 겹침(문맥 연속성 보강)\n",
    "    )\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "\n",
    "    # 2-3) E5 모델 권장 프리픽스 적용\n",
    "    # - 검색 대상 문서엔 'passage: '를 붙여 임베딩\n",
    "    splits_e5 = [\n",
    "        Document(page_content=\"passage: \" + d.page_content, metadata=d.metadata)\n",
    "        for d in splits\n",
    "    ]\n",
    "\n",
    "    # 2-4) FAISS 인덱스 생성 및 디스크 저장(다음번부터는 빠르게 로드 가능)\n",
    "    vectorstore = FAISS.from_documents(splits_e5, embedding)\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "    print(f\"💾 벡터스토어 저장 완료: {VECTORSTORE_PATH}\")\n",
    "\n",
    "# 2-5) 검색기(retriever) 구성\n",
    "# - search_type=\"mmr\"(Maximal Marginal Relevance): 유사성과 다양성 균형\n",
    "# - k: 최종 반환 문서 수, fetch_k: 후보군에서 먼저 많이 뽑아 다양성 최적화\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 10, \"fetch_k\": 20}\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) LLM(Ollama) 준비\n",
    "# =========================\n",
    "# - 로컬에서 Ollama가 실행 중이어야 하며 `gpt-oss` 모델이 설치되어 있어야 함\n",
    "#   (없다면 `ollama pull gpt-oss` 후 `ollama run gpt-oss`로 확인)\n",
    "# - 기본 포트가 아닐 때는: Ollama(model=\"gpt-oss\", base_url=\"http://127.0.0.1:11434\")\n",
    "llm = Ollama(model=\"gpt-oss\")\n",
    "\n",
    "# =========================\n",
    "# 4) 헬퍼 함수들 (파서/검색/문맥 병합)\n",
    "# =========================\n",
    "\n",
    "def _extract_json_array(text: str):\n",
    "    \"\"\"\n",
    "    LLM 출력 본문에서 '최상위 JSON 배열' 형태([ ... ])를 찾아 파싱합니다.\n",
    "    - 정규식은 대괄호로 감싼 첫 배열을 느슨하게 포착합니다.\n",
    "    - LLM이 JSON 앞뒤로 설명을 덧붙이는 경우를 대비합니다.\n",
    "    - 실패 시 None 반환.\n",
    "    \"\"\"\n",
    "    s = str(text)\n",
    "\n",
    "    # 코드펜스 안쪽 JSON 먼저 시도\n",
    "    fence_match = re.search(r\"```(?:json)?\\s*(\\[[\\s\\S]*?\\])\\s*```\", s, flags=re.IGNORECASE)\n",
    "    if fence_match:\n",
    "        try:\n",
    "            return json.loads(fence_match.group(1))\n",
    "        except Exception:\n",
    "            pass  # 아래 일반 로직으로 재시도\n",
    "\n",
    "    # 최상위 '[' 찾기\n",
    "    start = s.find('[')\n",
    "    if start == -1:\n",
    "        return None\n",
    "\n",
    "    depth = 0\n",
    "    end = -1\n",
    "    for i in range(start, len(s)):\n",
    "        ch = s[i]\n",
    "        if ch == '[':\n",
    "            depth += 1\n",
    "        elif ch == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                end = i + 1\n",
    "                break\n",
    "\n",
    "    if end == -1:\n",
    "        return None\n",
    "\n",
    "    candidate = s[start:end]\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_dangers_from_query(query: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    (1단계) 도로주행 상황 설명으로부터 '사고 위험 순간' 리스트를 LLM으로 추출합니다.\n",
    "    - 출력은 가능한 한 JSON 배열(문자열 리스트) 형태를 기대합니다.\n",
    "    - JSON 파싱이 실패하면 불릿(•/-) 라인을 폴백으로 일부 수집합니다.\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "당신은 도로교통법 기반 사고 위험 분석가입니다.\n",
    "아래 도로주행상황설명 텍스트는 영상을 시간순으로 보며 운전자 시점에서 벌어지는 상황을 나열한 것입니다. 운전자 시점에서 상황을 이해하세요.\n",
    "도로 주행 시 운전자가 마주하는 사고 위험 순간이 있습니다. **사고 위험 순간**을 리스트로 정리해주세요.\n",
    "'사고 위험 순간'만 핵심 키워드 중심으로 1~8개 목록으로 뽑아주세요.\n",
    "- 시간순\n",
    "- 출력은 JSON 배열(문자열 리스트)만\n",
    "\n",
    "텍스트:\n",
    "{query}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate.from_template(template).format(query=query.strip())\n",
    "    raw = str(llm.invoke(prompt))  # Ollama LLM 호출 → 문자열 결과\n",
    "\n",
    "    # 1) JSON 배열 시도\n",
    "    arr = _extract_json_array(raw)\n",
    "    if arr and isinstance(arr, list):\n",
    "        # 각 항목 문자열 정리(양쪽 공백 제거 및 빈 항목 제거)\n",
    "        return [str(x).strip() for x in arr if str(x).strip()]\n",
    "\n",
    "    # 2) 실패 시: 줄 단위로 나눠 불릿 라인만 추려서 최대 6개까지 폴백\n",
    "    lines = [l.strip(\"-• \\n\\r\\t\") for l in str(raw).splitlines() if l.strip()]\n",
    "    return [l for l in lines if len(l) > 1][:6]\n",
    "\n",
    "def retrieve_law_context_for_items(items: list[str], top_k_per_item: int = 5) -> list[Document]:\n",
    "    \"\"\"\n",
    "    (2단계-1) 각 항목(질문/선택지 등)을 쿼리로 삼아 RAG 검색을 수행하고,\n",
    "    중복 문서를 제거한 뒤 합친 리스트를 반환합니다.\n",
    "\n",
    "    - 'query: ' 프리픽스를 붙여 E5 모델 쿼리 최적화\n",
    "    - seen 집합으로 (페이지, 문서 앞부분) 키를 사용해 중복 제거\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    merged_docs: list[Document] = []\n",
    "    for it in items:\n",
    "        q = f\"query: {it}\"\n",
    "        docs = retriever.get_relevant_documents(q)[:top_k_per_item]\n",
    "        for d in docs:\n",
    "            key = (\n",
    "                d.metadata.get(\"page_label\", d.metadata.get(\"page\")),  # 페이지 번호(라벨 없으면 page)\n",
    "                d.page_content[:100],                                   # 문서 앞 100자(간단 중복 키)\n",
    "            )\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                merged_docs.append(d)\n",
    "    return merged_docs\n",
    "\n",
    "def join_docs(docs: list[Document]) -> str:\n",
    "    \"\"\"\n",
    "    (2단계-2) 문서 리스트를 사람이 읽기 쉬운 하나의 문자열로 병합합니다.\n",
    "    - 각 문서 앞에 [페이지 N] 헤더를 붙여 근거 위치를 추적 가능하게 함\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page_label\", d.metadata.get(\"page\"))\n",
    "        parts.append(f\"[페이지 {page}]\\n{d.page_content}\")\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "# =========================\n",
    "# 5) Logic B 본체\n",
    "# =========================\n",
    "def run_logic_b(query: str):\n",
    "    \"\"\"\n",
    "    전체 파이프라인 실행:\n",
    "      (1) 위험 상황 추출 → (2) 객관식 문제 생성(JSON) → (3) RAG 문맥 기반 해설 생성\n",
    "    \"\"\"\n",
    "\n",
    "    # (1) LLM으로 '사고 위험 순간' 리스트 추출\n",
    "    dangers = extract_dangers_from_query(query)\n",
    "    print(\"🔎 추출된 사고 위험 상황:\")\n",
    "    pprint(dangers)\n",
    "\n",
    "    if not dangers:\n",
    "        print(\"⚠️ 위험 상황을 추출하지 못했습니다.\")\n",
    "        return\n",
    "\n",
    "    # (2) 각 위험 상황을 바탕으로 '정답 1, 오답 3'의 객관식 문제를 생성\n",
    "    #     - 여기서는 해설/법령 인용 없이 문제 JSON만 받습니다.\n",
    "    make_question_tpl = \"\"\"\n",
    "        당신은 도로교통법 기반 객관식 문제 출제자입니다.\n",
    "        아래 '사고 위험 순간' 각각에 대해, 운전자 시점의 '사고 위험 직전 올바른 행동'을 맞히는 객관식 문제를 1개씩 만드세요.\n",
    "        - 객관식 문제의 선택지는 정답(운전자의 올바른 행동) 1개, 오답(운전자의 잘못된 행동) 3개로 만들어주세요.\n",
    "        - 운전자의 올바른 행동은 도로교통법 조문에 근거한 행동이어야 합니다. 운전자의 잘못된 행동은 위법,위협,사고유발 행동이어야 합니다.\n",
    "        - 아직 해설/법령 인용은 작성하지 마세요\n",
    "        - 출력은 JSON 배열로, 각 원소는 {{\"danger\": \"...\", \"question\": \"...\", \"choices\": [\"A. ...\",\"B. ...\",\"C. ...\",\"D. ...\"], \"answer\": \"A\"}} 형태\n",
    "\n",
    "        사고 위험 순간 목록:\n",
    "        {dangers}\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "    q_prompt = PromptTemplate.from_template(make_question_tpl).format(\n",
    "        dangers=\"\\n\".join(f\"- {d}\" for d in dangers)\n",
    "    )\n",
    "    raw = str(llm.invoke(q_prompt))     # 문제 생성 LLM 호출\n",
    "    questions = _extract_json_array(raw) or []  # JSON 배열 파싱 실패 시 빈 리스트\n",
    "\n",
    "    if not questions:\n",
    "        print(\"⚠️ 문제 생성을 파싱하지 못했습니다. 원문 출력:\")\n",
    "        print(raw)\n",
    "        return\n",
    "\n",
    "    print(\"\\n📝 생성된 문제(요약):\")\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        print(f\"{i}. [{q.get('danger')}] {q.get('question')} / 정답: {q.get('answer')}\")\n",
    "\n",
    "    print(\"[DEBUG] questions 갯수:\", len(questions))\n",
    "    if not questions:\n",
    "        print(\"[DEBUG] 원문:\", raw[:1000])\n",
    "\n",
    "\n",
    "    # (3) 각 문제에 대해: 질문/선택지/정답을 묶어 RAG 검색 → 법령 컨텍스트로 해설 생성\n",
    "    explain_tpl = \"\"\"\n",
    "        당신은 도로교통법 전문가입니다.\n",
    "        다음은 도로교통법 문서에서 검색된 일부 조항과 문장입니다:\n",
    "\n",
    "        {context}\n",
    "\n",
    "        아래 문제에 대해 해설만 작성하세요. 각 선택지에 대해:\n",
    "        1. 정답 선지의 경우, 왜 정답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 정답인 이유를 설명하세요.\n",
    "        2. 오답 선지의 경우, 왜 오답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 오답인 이유를 설명하세요.\n",
    "        3. 답변은 한국어로 해주세요.\n",
    "\n",
    "        문제:\n",
    "        {question}\n",
    "        선택지:\n",
    "        {choices}\n",
    "        정답: {answer}\n",
    "        \"\"\"\n",
    "\n",
    "    print(\"\\n\\n======= Logic B 결과 =======\")\n",
    "    for idx, q in enumerate(questions, 1):\n",
    "        # 3-1) 문제/선택지/정답을 하나의 쿼리로 결합 → RAG 검색 강화를 위해 사용\n",
    "        query_for_rag = f\"{q.get('question','')} 선택지: {' '.join(q.get('choices',[]))} 정답: {q.get('answer','')}\"\n",
    "        law_docs = retrieve_law_context_for_items([query_for_rag], top_k_per_item=5)\n",
    "\n",
    "        print(\"[DEBUG] law_docs 갯수:\", len(law_docs))\n",
    "\n",
    "        # 3-2) 컨텍스트 생성 (먼저 만들고 나서 미리보기 출력)\n",
    "        context = join_docs(law_docs)\n",
    "        preview = (context[:500].replace(\"\\n\", \" \") + \" ...\") if context else \"(empty)\"\n",
    "        print(\"[DEBUG] context 미리보기:\", preview)\n",
    "\n",
    "        # 3-3) 해설 생성\n",
    "        prompt = PromptTemplate.from_template(explain_tpl).format(\n",
    "            context=context if context else \"검색된 법령 문맥이 비어 있습니다.\",\n",
    "            question=q.get(\"question\", \"\"),\n",
    "            choices=\"\\n\".join(q.get(\"choices\", [])),\n",
    "            answer=q.get(\"answer\", \"\"),\n",
    "        )\n",
    "        explanation = llm.invoke(prompt)\n",
    "\n",
    "        # 3-4) 출력 정리\n",
    "        print(f\"\\n--- 문제 {idx} ---\")\n",
    "        print(f\"[위험상황] {q.get('danger')}\")\n",
    "        print(f\"[문제] {q.get('question')}\")\n",
    "        print(\"[선택지]\")\n",
    "        for c in q.get(\"choices\", []):\n",
    "            print(c)\n",
    "        print(f\"[정답] {q.get('answer')}\")\n",
    "        print(\"[해설]\")\n",
    "        print(explanation)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) 셀 실행 시 바로 테스트 실행\n",
    "#    ※ 실제 사용 시, 아래 query 텍스트만 교체하시면 됩니다.\n",
    "# =========================\n",
    "query = \"\"\"\n",
    "\n",
    "    에고 차량은 3차선 도로의 중간 차선을 주행합니다. \n",
    "    에고 차량이 차선을 바꿔 버스 전용차로로 주행합니다.\n",
    "    보행자가 갑자기 무단횡단하여 버스 전용차로 도로로 들어서고, 자아 차량과 보행자 간의 충돌이 발생합니다. \n",
    "    보행자가 바닥에 쓰러지고 에고 차량은 주행을 멈춥니다.\n",
    "\n",
    "    \"\"\"\n",
    "run_logic_b(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f052709",
   "metadata": {},
   "source": [
    "## 로직 C (도로주행 텍스트 -> RAG 기반 객관식 문제 생성 -> 각각 문제에 대해 RAG 기반 해설 찾기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ddbe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 기존 벡터스토어 로드 중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 346\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# 7) 실행 예시 (셀 하단에서 바로 실행)\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m    340\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124m에고 차량은 3차선 도로의 중간 차선을 주행합니다.\u001b[39m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124m에고 차량이 차선을 바꿔 버스 전용차로로 주행합니다.\u001b[39m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124m보행자가 갑자기 무단횡단하여 버스 전용차로 도로로 들어서고, 자아 차량과 보행자 간의 충돌이 발생합니다.\u001b[39m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124m보행자가 바닥에 쓰러지고 에고 차량은 주행을 멈춥니다.\u001b[39m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 346\u001b[0m \u001b[43mrun_new_logic_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 254\u001b[0m, in \u001b[0;36mrun_new_logic_b\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# [1-2] 문항(플레인 텍스트) 생성\u001b[39;00m\n\u001b[0;32m    253\u001b[0m gen_prompt \u001b[38;5;241m=\u001b[39m MAKE_TXT_PROMPT\u001b[38;5;241m.\u001b[39mformat(context\u001b[38;5;241m=\u001b[39mbase_context, query\u001b[38;5;241m=\u001b[39mquery\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m--> 254\u001b[0m gen_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mllm_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_prompt\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# 디버그: 원문 출력(원하면 주석 해제)\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# print(\"===== 모델 원문 출력 =====\")\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# print(gen_text)\u001b[39;00m\n\u001b[0;32m    260\u001b[0m dangers \u001b[38;5;241m=\u001b[39m parse_dangers(gen_text)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:389\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    386\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    387\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    390\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    391\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    392\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    393\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    394\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    395\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    396\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    397\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    398\u001b[0m         )\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    401\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:971\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    958\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    959\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    969\u001b[0m         )\n\u001b[0;32m    970\u001b[0m     ]\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    972\u001b[0m         prompts,\n\u001b[0;32m    973\u001b[0m         stop,\n\u001b[0;32m    974\u001b[0m         run_managers,\n\u001b[0;32m    975\u001b[0m         new_arg_supported\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    979\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    980\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    981\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[0;32m    989\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 792\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    793\u001b[0m                 prompts,\n\u001b[0;32m    794\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    795\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    796\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    797\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    798\u001b[0m             )\n\u001b[0;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    801\u001b[0m         )\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:437\u001b[0m, in \u001b[0;36mOllama._generate\u001b[1;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m--> 437\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_stream_with_aggregation(\n\u001b[0;32m    438\u001b[0m         prompt,\n\u001b[0;32m    439\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    440\u001b[0m         images\u001b[38;5;241m=\u001b[39mimages,\n\u001b[0;32m    441\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    442\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:349\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    342\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    347\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[0;32m    348\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m    351\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:194\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[1;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    188\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    192\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    193\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[0;32m    196\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    197\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    199\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[0;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[0;32m    871\u001b[0m ):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\requests\\utils.py:562\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    561\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    563\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\urllib3\\response.py:1088\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1088\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\urllib3\\response.py:1248\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1245\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\AI_GO_model\\.venv\\lib\\site-packages\\urllib3\\response.py:1167\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1167\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Jupyter one-cell runner for NEW Logic B (No-JSON version, robust regex parsing)\n",
    "# ------------------------------------------------------------------------------------\n",
    "# 1) query로 RAG → 법령 컨텍스트 확보\n",
    "# 2) LLM이 \"플레인 텍스트 스키마\"로 위험순간 + 객관식 문항들 생성 (JSON 금지)\n",
    "# 3) 각 문항 텍스트로 재-RAG → 문항별 해설 생성\n",
    "# - 출력 파싱은 간단한 정규식 기반(번호 목록 + Q/A 블록)\n",
    "# - 실패 시 폴백: 최소 1문항이라도 생성하도록 안전장치\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "import os, re, json, warnings\n",
    "from typing import List, Dict, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# 0) 경로/디바이스 설정\n",
    "# =========================\n",
    "VECTORSTORE_PATH = \"./vectorstore_cache\"\n",
    "PDF_PATH = r\"도로교통법(법률)(제20677호).pdf\"\n",
    "QUIZ_PATH = r\"운전면허_문제은행.csv\"\n",
    "\n",
    "DEVICE = \"cuda\" \n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    raise FileNotFoundError(f\"PDF를 찾을 수 없습니다: {PDF_PATH}\")\n",
    "\n",
    "# =========================\n",
    "# 1) 임베딩 모델 (E5)\n",
    "# =========================\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\"device\": DEVICE},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) 벡터스토어 로드/생성 (FAISS)\n",
    "# =========================\n",
    "if os.path.exists(VECTORSTORE_PATH):\n",
    "    print(\"✅ 기존 벡터스토어 로드 중...\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VECTORSTORE_PATH,\n",
    "        embedding,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    print(\"⚡ 신규 벡터스토어 생성 중...\")\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    pages = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"제\", \"조\", \"\\n\\n\", \"\\n\"],\n",
    "        chunk_size=1200,\n",
    "        chunk_overlap=200,\n",
    "    )\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "\n",
    "    splits_e5 = [\n",
    "        Document(page_content=\"passage: \" + d.page_content, metadata=d.metadata)\n",
    "        for d in splits\n",
    "    ]\n",
    "\n",
    "    vectorstore = FAISS.from_documents(splits_e5, embedding)\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "    print(f\"💾 벡터스토어 저장 완료: {VECTORSTORE_PATH}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 10, \"fetch_k\": 20}\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) LLM 구성 (Ollama)\n",
    "# =========================\n",
    "# 이제 JSON 금지 → 두 모델 모두 일반 텍스트 모드\n",
    "llm_gen = Ollama(model=\"gpt-oss\", temperature=0)  # 문항 생성\n",
    "llm_exp = Ollama(model=\"gpt-oss\", temperature=0)  # 해설 생성\n",
    "\n",
    "# =========================\n",
    "# 4) 유틸/파서\n",
    "# =========================\n",
    "def join_docs(docs: List[Document]) -> str:\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page_label\", d.metadata.get(\"page\"))\n",
    "        parts.append(f\"[페이지 {page}]\\n{d.page_content}\")\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "def build_context_from_query(query_text: str) -> str:\n",
    "    docs = retriever.get_relevant_documents(\"query: \" + query_text.strip())\n",
    "    if not docs: return \"\"\n",
    "    return join_docs(docs)\n",
    "\n",
    "def retrieve_law_context_for_items(items: List[str], top_k_per_item: int = 5) -> str:\n",
    "    seen = set()\n",
    "    merged: List[Document] = []\n",
    "    for it in items:\n",
    "        docs = retriever.get_relevant_documents(\"query: \" + it)[:top_k_per_item]\n",
    "        for d in docs:\n",
    "            key = (d.metadata.get(\"page_label\", d.metadata.get(\"page\")), d.page_content[:120])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                merged.append(d)\n",
    "    return join_docs(merged)\n",
    "\n",
    "# --- 파서: 위험순간/문항(플레인 텍스트) ---\n",
    "QA_BLOCK_RE = re.compile(\n",
    "    r\"\"\"^Q\\s*(\\d+)\\s*[:：]\\s*(?P<q>.+?)\\s*\n",
    "A[)\\.]?\\s*(?P<A>.+?)\\s*\n",
    "B[)\\.]?\\s*(?P<B>.+?)\\s*\n",
    "C[)\\.]?\\s*(?P<C>.+?)\\s*\n",
    "D[)\\.]?\\s*(?P<D>.+?)\\s*\n",
    "(?:ANS|정답)\\s*[:：]\\s*(?P<ans>[ABCD])\\s*\n",
    "(?:-{3,}\\s*)?\"\"\",\n",
    "    re.IGNORECASE | re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "def parse_dangers(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    [위험순간] 섹션에서 '1. ...' 형태의 라인들을 추출\n",
    "    \"\"\"\n",
    "    # 섹션 경계 찾기\n",
    "    m = re.search(r\"\\[위험\\s*순간\\]|\\[위험\\s*상황\\]|\\[DANGERS?\\]\", text, re.I)\n",
    "    if not m:\n",
    "        return []\n",
    "    start = m.end()\n",
    "    # 다음 섹션 시작까지(문항/QUESTIONS) 잘라내기\n",
    "    next_m = re.search(r\"\\[문항\\]|\\[문제\\]|\\[QUESTIONS?\\]\", text[start:], re.I)\n",
    "    dangers_block = text[start:] if not next_m else text[start:start+next_m.start()]\n",
    "    # 번호 라인 추출\n",
    "    items = []\n",
    "    for line in dangers_block.splitlines():\n",
    "        line = line.strip()\n",
    "        mline = re.match(r\"^\\d+\\.\\s*(.+)$\", line)\n",
    "        if mline:\n",
    "            items.append(mline.group(1).strip())\n",
    "    return items\n",
    "\n",
    "def parse_questions(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Qn/A/B/C/D/정답 블록을 모두 추출해 리스트로 반환\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for m in QA_BLOCK_RE.finditer(text):\n",
    "        q = {\n",
    "            \"idx\": int(m.group(1)),\n",
    "            \"question\": re.sub(r\"\\s+\", \" \", m.group(\"q\")).strip(),\n",
    "            \"choices\": {\n",
    "                \"A\": re.sub(r\"\\s+\", \" \", m.group(\"A\")).strip(),\n",
    "                \"B\": re.sub(r\"\\s+\", \" \", m.group(\"B\")).strip(),\n",
    "                \"C\": re.sub(r\"\\s+\", \" \", m.group(\"C\")).strip(),\n",
    "                \"D\": re.sub(r\"\\s+\", \" \", m.group(\"D\")).strip(),\n",
    "            },\n",
    "            \"answer\": m.group(\"ans\").upper()\n",
    "        }\n",
    "        results.append(q)\n",
    "    # idx 순 정렬\n",
    "    results.sort(key=lambda x: x[\"idx\"])\n",
    "    return results\n",
    "\n",
    "# =========================\n",
    "# 5) 프롬프트 (플레인 텍스트 스키마)\n",
    "# =========================\n",
    "MAKE_TXT_TPL = \"\"\"\n",
    "당신은 도로교통법 전문가 겸 문제 출제자입니다.\n",
    "아래 '법령 발췌(context)'와 '도로주행상황설명(query)'를 근거로,\n",
    "JSON, 표, 코드펜스 없이 **아래 형식** 그대로만 출력하세요.\n",
    "\n",
    "[형식 가이드 - 반드시 그대로]\n",
    "[위험순간]\n",
    "1. (운전자 시점 사고 위험 순간) \n",
    "2. ...\n",
    "(최대 8개)\n",
    "\n",
    "[문항]\n",
    "Q1: (문제 문장; 한 문장)\n",
    "A) (선지 A)\n",
    "B) (선지 B)\n",
    "C) (선지 C)\n",
    "D) (선지 D)\n",
    "정답: (A/B/C/D)\n",
    "---\n",
    "Q2: (문제 문장)\n",
    "A) ...\n",
    "B) ...\n",
    "C) ...\n",
    "D) ...\n",
    "정답: (A/B/C/D)\n",
    "(필요 개수만큼 반복; 최소 1문항)\n",
    "\n",
    "[주의]\n",
    "- JSON/마크다운/코드블록/표/불릿 금지, 위 형식 외 장식 금지\n",
    "- 선택지는 정확히 4개(A~D), 정답 1개\n",
    "- 올바른 행동(정답 선지)은 도로교통법에 근거, 잘못된 행동(오답 선지)은 불법, 위협 운전에 해당하도록\n",
    "-\n",
    "\n",
    "[법령 발췌(context)]\n",
    "{{context}}\n",
    "\n",
    "[도로주행상황설명(query)]\n",
    "{{query}}\n",
    "\"\"\"\n",
    "\n",
    "MAKE_TXT_PROMPT = PromptTemplate(\n",
    "    template=MAKE_TXT_TPL,\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template_format=\"jinja2\"\n",
    ")\n",
    "\n",
    "EXPLAIN_TPL = \"\"\"\n",
    "당신은 도로교통법 전문가입니다.\n",
    "아래 문항의 각 선택지에 대해 순수 텍스트로만 해설하세요. (마크다운/표/코드펜스 금지)\n",
    "\n",
    "요구:\n",
    "1) 정답: 왜 정답인지, 관련 조문을 \"도로교통법 제XX조 제X항 '문장 전체'\" 형식으로 1회 이상 정확히 인용 후 설명.\n",
    "2) 오답: 왜 오답인지, 동일 형식으로 관련 조문 인용 후 설명.\n",
    "3) 한국어\n",
    "\n",
    "# 법령 발췌(context)\n",
    "{context}\n",
    "\n",
    "문제: {question}\n",
    "선택지:\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "정답: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# 6) 실행 함수\n",
    "# =========================\n",
    "def run_new_logic_b(query: str):\n",
    "    # [1] query → 광의 컨텍스트\n",
    "    base_context = build_context_from_query(query)\n",
    "    if not base_context:\n",
    "        print(\"⚠️ RAG에서 컨텍스트를 찾지 못했습니다. (PDF/인덱스/VECTORSTORE_PATH 확인)\")\n",
    "        return\n",
    "\n",
    "    # [1-2] 문항(플레인 텍스트) 생성\n",
    "    gen_prompt = MAKE_TXT_PROMPT.format(context=base_context, query=query.strip())\n",
    "    gen_text = str(llm_gen.invoke(gen_prompt)).strip()\n",
    "\n",
    "    # 디버그: 원문 출력(원하면 주석 해제)\n",
    "    # print(\"===== 모델 원문 출력 =====\")\n",
    "    # print(gen_text)\n",
    "\n",
    "    dangers = parse_dangers(gen_text)\n",
    "    questions = parse_questions(gen_text)\n",
    "\n",
    "    # 폴백: 문항이 0개면 1문항을 강제로 생성하도록 간단 재요청\n",
    "    if not questions:\n",
    "        fallback_tpl = \"\"\"\n",
    "다음 상황에 대해 객관식 1문항만 위 형식으로 출력하세요.\n",
    "\n",
    "[문항]\n",
    "Q1: (문제 문장)\n",
    "A) ...\n",
    "B) ...\n",
    "C) ...\n",
    "D) ...\n",
    "정답: (A/B/C/D)\n",
    "\n",
    "[법령 발췌(context)]\n",
    "{context}\n",
    "\n",
    "[상황]\n",
    "{query}\n",
    "\"\"\"\n",
    "        fb_text = str(llm_gen.invoke(fallback_tpl.format(context=base_context, query=query.strip()))).strip()\n",
    "        questions = parse_questions(fb_text)\n",
    "\n",
    "    if not questions:\n",
    "        print(\"⚠️ 문항을 생성/파싱하지 못했습니다. 모델 출력 확인 필요.\")\n",
    "        print(\"=== 생성 텍스트 ===\")\n",
    "        print(gen_text[:1500] + (\"... [truncated]\" if len(gen_text) > 1500 else \"\"))\n",
    "        return\n",
    "\n",
    "    # 요약 출력\n",
    "    print(\"🧭 위험순간(파싱 결과):\")\n",
    "    if dangers:\n",
    "        for i, d in enumerate(dangers, 1):\n",
    "            print(f\"{i}. {d}\")\n",
    "    else:\n",
    "        print(\"(위험순간 섹션을 찾지 못했거나 비어 있음)\")\n",
    "\n",
    "    print(\"\\n📝 생성 문항(요약):\")\n",
    "    for q in questions:\n",
    "        print(f\"Q{q['idx']} | 정답={q['answer']} | {q['question'][:60]}...\")\n",
    "\n",
    "    # [2] 각 문항을 다시 질의로 재-RAG → 해설 생성\n",
    "    print(\"\\n\\n======= 최종 결과 =======\")\n",
    "    for q in questions:\n",
    "        question_text = q[\"question\"]\n",
    "        choices_dict = q[\"choices\"]\n",
    "        answer_key = q[\"answer\"]\n",
    "\n",
    "        # 재-RAG 질의\n",
    "        query_for_rag = f\"{question_text} 선택지: A){choices_dict['A']} B){choices_dict['B']} C){choices_dict['C']} D){choices_dict['D']} 정답:{answer_key}\"\n",
    "        per_question_context = retrieve_law_context_for_items([query_for_rag], top_k_per_item=5)\n",
    "\n",
    "        # 해설 프롬프트\n",
    "        exp_prompt = EXPLAIN_TPL.format(\n",
    "            context=per_question_context,\n",
    "            question=question_text,\n",
    "            A=choices_dict[\"A\"],\n",
    "            B=choices_dict[\"B\"],\n",
    "            C=choices_dict[\"C\"],\n",
    "            D=choices_dict[\"D\"],\n",
    "            answer=answer_key\n",
    "        )\n",
    "        explanation = llm_exp.invoke(exp_prompt)\n",
    "\n",
    "        # 출력\n",
    "        print(f\"\\n--- 문제 {q['idx']} ---\")\n",
    "        print(f\"[문제] {question_text}\")\n",
    "        print(\"A)\", choices_dict[\"A\"])\n",
    "        print(\"B)\", choices_dict[\"B\"])\n",
    "        print(\"C)\", choices_dict[\"C\"])\n",
    "        print(\"D)\", choices_dict[\"D\"])\n",
    "        print(f\"[정답] {answer_key}\")\n",
    "        print(\"[해설]\")\n",
    "        print(explanation)\n",
    "\n",
    "# =========================\n",
    "# 7) 실행 예시 (셀 하단에서 바로 실행)\n",
    "# =========================\n",
    "query = \"\"\"\n",
    "에고 차량은 3차선 도로의 중간 차선을 주행합니다.\n",
    "에고 차량이 차선을 바꿔 버스 전용차로로 주행합니다.\n",
    "보행자가 갑자기 무단횡단하여 버스 전용차로 도로로 들어서고, 자아 차량과 보행자 간의 충돌이 발생합니다.\n",
    "보행자가 바닥에 쓰러지고 에고 차량은 주행을 멈춥니다.\n",
    "\"\"\"\n",
    "run_new_logic_b(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af610ec",
   "metadata": {},
   "source": [
    "# 꼬리 문제 형태로\n",
    "- 상황 설명 텍스트 -> 문제 1개 만들기\n",
    "- 상황 설명 텍스트에 나온 키워드 기반으로 키워드와 관련된 퀴즈 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84af0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb595b7",
   "metadata": {},
   "source": [
    "# 조 단위로 벡터 저장\n",
    "\n",
    "- 조(條)” 단위로 부모 문서를 만들고, 그 안을 작은 청크(자식)로 쪼개서 검색은 자식으로 하되 **반환은 항상 ‘해당 조 전체(부모)’**가 오도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Jupyter one-cell runner for logic_b (조(條) 단위 Parent Retrieval 통합)\n",
    "# -------------------------------------------------------------\n",
    "# - PDF를 '제N조' 단위(부모)로 파싱하여 원문을 보존\n",
    "# - 각 조 내부를 청킹(자식) → FAISS 색인(자식에는 E5 'passage:' 프리픽스)\n",
    "# - 검색 시: MMR로 '자식'을 찾고 → 해당 '부모(조 전체)'를 반환\n",
    "# - 나머지 파이프라인(위험 순간 추출, 문제 생성, RAG 해설)은 동일\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # langchain>=0.2\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# 0) 경로/환경 설정\n",
    "# =========================\n",
    "VECTORSTORE_PATH = \"./vectorstore_cache\"           # FAISS 인덱스 저장 폴더\n",
    "PARENT_STORE_PATH = \"./parent_articles_store.json\" # ★ 부모(조) 원문 저장 파일\n",
    "PDF_PATH = r\"도로교통법(법률)(제20677호).pdf\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"PDF를 찾을 수 없습니다: {PDF_PATH}\\n\"\n",
    "        f\"- 노트북과 같은 폴더에 두거나 PDF_PATH를 수정하세요.\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# 1) 임베딩 모델 (E5)\n",
    "# =========================\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) '제N조' 단위 파서 (부모 생성) ★\n",
    "# =========================\n",
    "ARTICLE_PATTERN = re.compile(\n",
    "    r\"(제\\s*\\d+\\s*조(?:\\s*\\[[^\\]]+\\])?(?:\\s*\\([^)]+\\))?)\\s*(.*?)(?=제\\s*\\d+\\s*조|\\Z)\",\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "def load_articles_as_parents(pdf_path: str) -> List[Document]:\n",
    "    \"\"\"PDF 전체를 이어 붙여 '제N조' 단위로 부모 문서를 만든다.\"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    full_text = \"\".join(p.page_content for p in pages)\n",
    "\n",
    "    parents: List[Document] = []\n",
    "    for m in ARTICLE_PATTERN.finditer(full_text):\n",
    "        header = m.group(1).strip()   # \"제1조(목적)\" 등\n",
    "        body   = m.group(2).strip()\n",
    "\n",
    "        num_m = re.search(r\"제\\s*(\\d+)\\s*조\", header)\n",
    "        title_m = re.search(r\"제\\s*\\d+\\s*조\\s*\\(([^)]+)\\)\", header)\n",
    "        article_no = int(num_m.group(1)) if num_m else None\n",
    "        article_title = title_m.group(1) if title_m else None\n",
    "\n",
    "        parent_id = f\"article_{article_no if article_no is not None else header}\"\n",
    "\n",
    "        parents.append(\n",
    "            Document(\n",
    "                page_content=f\"{header}\\n{body}\",\n",
    "                metadata={\n",
    "                    \"unit\": \"article\",\n",
    "                    \"article_no\": article_no,\n",
    "                    \"article_header\": header,\n",
    "                    \"article_title\": article_title,\n",
    "                    \"parent_id\": parent_id,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    return parents\n",
    "\n",
    "# =========================\n",
    "# 3) 부모 저장/로드 유틸 ★\n",
    "# =========================\n",
    "def save_parents(parents: List[Document], path: str):\n",
    "    data = []\n",
    "    for d in parents:\n",
    "        data.append({\n",
    "            \"page_content\": d.page_content,\n",
    "            \"metadata\": d.metadata\n",
    "        })\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_parents(path: str) -> Dict[str, Document]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    parents_dict = {}\n",
    "    for item in data:\n",
    "        meta = item.get(\"metadata\", {})\n",
    "        pid = meta.get(\"parent_id\")\n",
    "        if pid:\n",
    "            parents_dict[pid] = Document(\n",
    "                page_content=item.get(\"page_content\", \"\"),\n",
    "                metadata=meta\n",
    "            )\n",
    "    return parents_dict\n",
    "\n",
    "# =========================\n",
    "# 4) 인덱스 준비 (자식 청크 생성 + FAISS) ★\n",
    "# =========================\n",
    "def build_child_chunks_from_parents(parents: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    각 부모(조)를 청킹하여 '자식' Document 리스트를 만든다.\n",
    "    - 자식 텍스트에는 E5 'passage:' 프리픽스 적용\n",
    "    - 메타데이터에 parent_id/조번호/헤더 등을 계승\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=120,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]\n",
    "    )\n",
    "    childs: List[Document] = []\n",
    "    for p in parents:\n",
    "        sub_docs = splitter.split_text(p.page_content)\n",
    "        for idx, chunk in enumerate(sub_docs):\n",
    "            childs.append(\n",
    "                Document(\n",
    "                    page_content=\"passage: \" + chunk,  # ★ E5 권장 프리픽스\n",
    "                    metadata={\n",
    "                        **p.metadata,\n",
    "                        \"unit\": \"article_child\",\n",
    "                        \"child_idx\": idx\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "    return childs\n",
    "\n",
    "# 벡터스토어/부모 스토어 준비\n",
    "if os.path.exists(VECTORSTORE_PATH) and os.path.exists(PARENT_STORE_PATH):\n",
    "    print(\"✅ 기존 벡터스토어 + 부모조 저장소 로드 중...\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VECTORSTORE_PATH, embedding, allow_dangerous_deserialization=True\n",
    "    )\n",
    "    parents_dict = load_parents(PARENT_STORE_PATH)  # parent_id -> Document\n",
    "else:\n",
    "    print(\"⚡ 신규 인덱스 생성 중...(조 단위 파싱 → 자식 청킹 → FAISS 색인)\")\n",
    "    parents = load_articles_as_parents(PDF_PATH)         # 부모(조)\n",
    "    child_chunks = build_child_chunks_from_parents(parents)  # 자식(청크)\n",
    "\n",
    "    # FAISS 색인 생성 (자식)\n",
    "    vectorstore = FAISS.from_documents(child_chunks, embedding)\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "    print(f\"💾 벡터스토어 저장 완료: {VECTORSTORE_PATH}\")\n",
    "\n",
    "    # 부모 저장(JSON)\n",
    "    save_parents(parents, PARENT_STORE_PATH)\n",
    "    parents_dict = {d.metadata[\"parent_id\"]: d for d in parents}\n",
    "    print(f\"💾 부모(조) 저장 완료: {PARENT_STORE_PATH}\")\n",
    "\n",
    "# =========================\n",
    "# 5) '부모 반환' 래퍼 리트리버 ★\n",
    "# =========================\n",
    "class ParentByArticleRetriever:\n",
    "    \"\"\"\n",
    "    - 내부적으로 FAISS에서 '자식'을 MMR로 검색\n",
    "    - 결과의 parent_id를 모아 '부모(조 전체)' Document를 반환\n",
    "    \"\"\"\n",
    "    def __init__(self, vectorstore: FAISS, parents: Dict[str, Document],\n",
    "                 k: int = 10, fetch_k: int = 20):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.parents = parents\n",
    "        self.k = k\n",
    "        self.fetch_k = fetch_k\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        q = query if query.strip().startswith(\"query:\") else (\"query: \" + query.strip())\n",
    "        # MMR 검색 (다양성 확보)\n",
    "        try:\n",
    "            child_docs = self.vectorstore.max_marginal_relevance_search(\n",
    "                q, k=self.k, fetch_k=self.fetch_k\n",
    "            )\n",
    "        except Exception:\n",
    "            # 호환 안 되면 일반 유사도 검색으로 폴백\n",
    "            child_docs = self.vectorstore.similarity_search(q, k=self.k)\n",
    "\n",
    "        parent_ids = []\n",
    "        seen = set()\n",
    "        for d in child_docs:\n",
    "            pid = d.metadata.get(\"parent_id\")\n",
    "            if pid and pid not in seen and pid in self.parents:\n",
    "                seen.add(pid)\n",
    "                parent_ids.append(pid)\n",
    "\n",
    "        # 부모(조 전체) 반환\n",
    "        return [self.parents[pid] for pid in parent_ids]\n",
    "\n",
    "# 기존 retriever 대체\n",
    "retriever = ParentByArticleRetriever(vectorstore, parents_dict, k=10, fetch_k=20)\n",
    "\n",
    "# =========================\n",
    "# 6) LLM(Ollama)\n",
    "# =========================\n",
    "llm = Ollama(model=\"gpt-oss\")\n",
    "\n",
    "# =========================\n",
    "# 7) 헬퍼(기존 코드 유지)\n",
    "# =========================\n",
    "def _extract_json_array(text: str):\n",
    "    s = str(text)\n",
    "    fence_match = re.search(r\"```(?:json)?\\s*(\\[[\\s\\S]*?\\])\\s*```\", s, flags=re.IGNORECASE)\n",
    "    if fence_match:\n",
    "        try:\n",
    "            return json.loads(fence_match.group(1))\n",
    "        except Exception:\n",
    "            pass\n",
    "    start = s.find('[')\n",
    "    if start == -1:\n",
    "        return None\n",
    "    depth = 0\n",
    "    end = -1\n",
    "    for i in range(start, len(s)):\n",
    "        ch = s[i]\n",
    "        if ch == '[':\n",
    "            depth += 1\n",
    "        elif ch == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                end = i + 1\n",
    "                break\n",
    "    if end == -1:\n",
    "        return None\n",
    "    candidate = s[start:end]\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_dangers_from_query(query: str) -> List[str]:\n",
    "    template = \"\"\"\n",
    "당신은 도로교통법 기반 사고 위험 분석가입니다.\n",
    "아래 도로주행상황설명 텍스트는 영상을 시간순으로 보며 운전자 시점에서 벌어지는 상황을 나열한 것입니다. 운전자 시점에서 상황을 이해하세요.\n",
    "도로 주행 시 운전자가 마주하는 사고 위험 순간이 있습니다. **사고 위험 순간**을 리스트로 정리해주세요.\n",
    "'사고 위험 순간'만 핵심 키워드 중심으로 1~8개 목록으로 뽑아주세요.\n",
    "- 시간순\n",
    "- 출력은 JSON 배열(문자열 리스트)만\n",
    "\n",
    "텍스트:\n",
    "{query}\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate.from_template(template).format(query=query.strip())\n",
    "    raw = str(llm.invoke(prompt))\n",
    "    arr = _extract_json_array(raw)\n",
    "    if arr and isinstance(arr, list):\n",
    "        return [str(x).strip() for x in arr if str(x).strip()]\n",
    "    lines = [l.strip(\"-• \\n\\r\\t\") for l in str(raw).splitlines() if l.strip()]\n",
    "    return [l for l in lines if len(l) > 1][:6]\n",
    "\n",
    "def retrieve_law_context_for_items(items: List[str], top_k_per_item: int = 5) -> List[Document]:\n",
    "    \"\"\"\n",
    "    (부모 반환 리트리버 사용) 각 항목을 쿼리로 삼아 RAG 검색.\n",
    "    - 중복 부모(같은 조)는 제거\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    merged_docs: List[Document] = []\n",
    "    for it in items:\n",
    "        q = f\"query: {it}\"\n",
    "        docs = retriever.get_relevant_documents(q)[:top_k_per_item]\n",
    "        for d in docs:\n",
    "            key = d.metadata.get(\"parent_id\") or d.metadata.get(\"article_no\")\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                merged_docs.append(d)\n",
    "    return merged_docs\n",
    "\n",
    "def join_docs(docs: List[Document]) -> str:\n",
    "    \"\"\"부모(조) 문서를 사람이 읽기 좋게 병합.\"\"\"\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        header = d.metadata.get(\"article_header\", \"\")\n",
    "        no = d.metadata.get(\"article_no\", \"\")\n",
    "        parts.append(f\"[{header or f'제{no}조'}]\\n{d.page_content}\")\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "# =========================\n",
    "# 8) Logic B 본체 (기존 유지)\n",
    "# =========================\n",
    "def run_logic_b(query: str):\n",
    "    dangers = extract_dangers_from_query(query)\n",
    "    print(\"🔎 추출된 사고 위험 상황:\")\n",
    "    pprint(dangers)\n",
    "\n",
    "    if not dangers:\n",
    "        print(\"⚠️ 위험 상황을 추출하지 못했습니다.\")\n",
    "        return\n",
    "\n",
    "    make_question_tpl = \"\"\"\n",
    "당신은 도로교통법 기반 객관식 문제 출제자입니다.\n",
    "아래 '사고 위험 순간' 각각에 대해, 운전자 시점의 '사고 위험 직전 올바른 행동'을 맞히는 객관식 문제를 1개씩 만드세요.\n",
    "- 객관식 문제의 선택지는 정답(운전자의 올바른 행동) 1개, 오답(운전자의 잘못된 행동) 3개로 만들어주세요.\n",
    "- 운전자의 올바른 행동은 도로교통법 조문에 근거한 행동이어야 합니다. 운전자의 잘못된 행동은 위법,위협,사고유발 행동이어야 합니다.\n",
    "- 아직 해설/법령 인용은 작성하지 마세요\n",
    "- 출력은 JSON 배열로, 각 원소는 {\"danger\": \"...\", \"question\": \"...\", \"choices\": [\"A. ...\",\"B. ...\",\"C. ...\",\"D. ...\"], \"answer\": \"A\"} 형태\n",
    "\n",
    "사고 위험 순간 목록:\n",
    "{dangers}\n",
    "\"\"\"\n",
    "    q_prompt = PromptTemplate.from_template(make_question_tpl).format(\n",
    "        dangers=\"\\n\".join(f\"- {d}\" for d in dangers)\n",
    "    )\n",
    "    raw = str(llm.invoke(q_prompt))\n",
    "    questions = _extract_json_array(raw) or []\n",
    "    if not questions:\n",
    "        print(\"⚠️ 문제 생성을 파싱하지 못했습니다. 원문 출력:\")\n",
    "        print(raw)\n",
    "        return\n",
    "\n",
    "    print(\"\\n📝 생성된 문제(요약):\")\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        print(f\"{i}. [{q.get('danger')}] {q.get('question')} / 정답: {q.get('answer')}\")\n",
    "\n",
    "    explain_tpl = \"\"\"\n",
    "당신은 도로교통법 전문가입니다.\n",
    "다음은 도로교통법 문서에서 검색된 일부 조항(조 단위 원문)입니다:\n",
    "\n",
    "{context}\n",
    "\n",
    "아래 문제에 대해 해설만 작성하세요. 각 선택지에 대해:\n",
    "1. 정답 선지의 경우, 왜 정답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 정답인 이유를 설명하세요.\n",
    "2. 오답 선지의 경우, 왜 오답인지 도로교통법 조문을 인용해 \"도로교통법 제XX조 제X항 '문장 전체'\"를 반드시 그대로 인용 후 오답인 이유를 설명하세요.\n",
    "3. 답변은 한국어로 해주세요.\n",
    "\n",
    "문제:\n",
    "{question}\n",
    "선택지:\n",
    "{choices}\n",
    "정답: {answer}\n",
    "\"\"\"\n",
    "\n",
    "    print(\"\\n\\n======= Logic B 결과 =======\")\n",
    "    for idx, q in enumerate(questions, 1):\n",
    "        query_for_rag = f\"{q.get('question','')} 선택지: {' '.join(q.get('choices',[]))} 정답: {q.get('answer','')}\"\n",
    "        law_docs = retrieve_law_context_for_items([query_for_rag], top_k_per_item=5)\n",
    "        print(\"[DEBUG] law_docs(조 단위) 갯수:\", len(law_docs))\n",
    "\n",
    "        context = join_docs(law_docs)\n",
    "        preview = (context[:500].replace(\"\\n\", \" \") + \" ...\") if context else \"(empty)\"\n",
    "        print(\"[DEBUG] context 미리보기:\", preview)\n",
    "\n",
    "        prompt = PromptTemplate.from_template(explain_tpl).format(\n",
    "            context=context if context else \"검색된 법령 문맥이 비어 있습니다.\",\n",
    "            question=q.get(\"question\", \"\"),\n",
    "            choices=\"\\n\".join(q.get(\"choices\", [])),\n",
    "            answer=q.get(\"answer\", \"\"),\n",
    "        )\n",
    "        explanation = llm.invoke(prompt)\n",
    "\n",
    "        print(f\"\\n--- 문제 {idx} ---\")\n",
    "        print(f\"[위험상황] {q.get('danger')}\")\n",
    "        print(f\"[문제] {q.get('question')}\")\n",
    "        print(\"[선택지]\")\n",
    "        for c in q.get(\"choices\", []):\n",
    "            print(c)\n",
    "        print(f\"[정답] {q.get('answer')}\")\n",
    "        print(\"[해설]\")\n",
    "        print(explanation)\n",
    "\n",
    "# =========================\n",
    "# 9) 테스트 실행\n",
    "# =========================\n",
    "query = \"\"\"\n",
    "에고 차량은 3차선 도로의 중간 차선을 주행합니다. \n",
    "에고 차량이 차선을 바꿔 버스 전용차로로 주행합니다.\n",
    "보행자가 갑자기 무단횡단하여 버스 전용차로 도로로 들어서고, 자아 차량과 보행자 간의 충돌이 발생합니다. \n",
    "보행자가 바닥에 쓰러지고 에고 차량은 주행을 멈춥니다.\n",
    "\"\"\"\n",
    "run_logic_b(query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
